{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15905 rows exported for particle_detections.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "def get_config():\n",
    "    \"\"\"\n",
    "    Define input/output paths and parameters.\n",
    "    \"\"\"\n",
    "    input_video_path = '/Users/Ricardo/Desktop/Y4 Lab code/Cooldown 10/_video (0).mp4'\n",
    "    output_folder = '/Users/Ricardo/Desktop/Y4 Lab code/Work 0.3K'\n",
    "    # Vertical crop limits for the ROI\n",
    "    y_lower_limit = 100\n",
    "    y_upper_limit = 819\n",
    "    # Process frames from 0 to this index (inclusive)\n",
    "    end_frame = 300\n",
    "    # Detection parameters for small/big particles\n",
    "    params = {\n",
    "        'min_small_intensity': 18,\n",
    "        'min_big_intensity': 12,\n",
    "        'background_removal_small': True,\n",
    "        'background_removal_big': True,\n",
    "        'small_neighborhood_and_integration_size': (5, 5),\n",
    "        'big_neighborhood_and_integration_size': (9, 9),\n",
    "        'small_gaussian_blur_kernel_size': (13, 13),\n",
    "        'big_gaussian_blur_kernel_size': (13, 13),\n",
    "        'small_position_refinement_size': (9, 9),\n",
    "        'big_position_refinement_size': (9, 9),\n",
    "        'small_size': (5, 5),\n",
    "        'big_size': (9, 9),\n",
    "        'raw_luminosity_grid_size': (9, 9)\n",
    "    }\n",
    "    return input_video_path, output_folder, y_lower_limit, y_upper_limit, end_frame, params\n",
    "\n",
    "\n",
    "def find_local_minima(Z, neighborhood_size=(3,3)):\n",
    "    \"\"\"\n",
    "    Find local minima in a 2D array (image).\n",
    "    Uses morphological erosion to find pixels that are lower than or equal\n",
    "    to their neighbours.\n",
    "    \"\"\"\n",
    "    nh, nw = neighborhood_size\n",
    "    kernel = np.ones((nh, nw), dtype=np.uint8)\n",
    "    # Pixels equal to the eroded image are local minima\n",
    "    local_min = (cv2.erode(Z, kernel) == Z)\n",
    "    # Remove border artefacts where the neighbourhood would spill outside\n",
    "    local_min[:nh//2, :] = False\n",
    "    local_min[-(nh//2):, :] = False\n",
    "    local_min[:, :nw//2] = False\n",
    "    local_min[:, -(nw//2):] = False\n",
    "    return local_min\n",
    "\n",
    "\n",
    "def fit_quadratic_surface(Z_blurred, neighborhood_size=(3,3)):\n",
    "    \"\"\"\n",
    "    Fit a quadratic surface to local minima points of the image.\n",
    "    Used for background estimation/removal.\n",
    "    \"\"\"\n",
    "    # Construct coordinate grids\n",
    "    X, Y = np.meshgrid(np.arange(Z_blurred.shape[1]), np.arange(Z_blurred.shape[0]))\n",
    "    # Use minima as proxy for background locations\n",
    "    minima_mask = find_local_minima(Z_blurred, neighborhood_size)\n",
    "    X_min, Y_min, Z_min = X[minima_mask], Y[minima_mask], Z_blurred[minima_mask]\n",
    "\n",
    "    # Require enough points for least squares (6 params)\n",
    "    if X_min.size < 6:\n",
    "        return None\n",
    "\n",
    "    # Quadratic surface model: ax^2 + by^2 + cxy + dx + ey + f\n",
    "    A = np.c_[X_min**2, Y_min**2, X_min*Y_min, X_min, Y_min, np.ones_like(X_min)]\n",
    "    try:\n",
    "        coefficients, _, _, _ = np.linalg.lstsq(A, Z_min, rcond=None)\n",
    "    except np.linalg.LinAlgError:\n",
    "        return None\n",
    "    return coefficients\n",
    "\n",
    "\n",
    "def remove_background(Z, coefficients):\n",
    "    \"\"\"\n",
    "    Remove background using fitted quadratic surface.\n",
    "    Ensures negative pixel values are set to zero.\n",
    "    \"\"\"\n",
    "    a, b, c, d, e, f = coefficients\n",
    "    height, width = Z.shape\n",
    "    X, Y = np.meshgrid(np.arange(width), np.arange(height))\n",
    "\n",
    "    # Compute fitted background surface for the whole frame\n",
    "    Z_fit = a * X**2 + b * Y**2 + c * X * Y + d * X + e * Y + f\n",
    "    # Subtract background and clamp to [0, 255] via uint8 cast later\n",
    "    Z_corrected = Z.astype(np.float32) - Z_fit\n",
    "    Z_corrected[Z_corrected < 0] = 0\n",
    "    return Z_corrected.astype(np.uint8)\n",
    "\n",
    "\n",
    "def refine_centroid(frame, x, y, window_size=(5,5)):\n",
    "    \"\"\"\n",
    "    Refine particle centroid using image moments inside a local window.\n",
    "    Returns sub-pixel accurate coordinates.\n",
    "    \"\"\"\n",
    "    # Define local window bounds around the initial (x, y)\n",
    "    half_window_x = window_size[0] // 2\n",
    "    half_window_y = window_size[1] // 2\n",
    "    y_min = max(int(y) - half_window_y, 0)\n",
    "    y_max = min(int(y) + half_window_y + 1, frame.shape[0])\n",
    "    x_min = max(int(x) - half_window_x, 0)\n",
    "    x_max = min(int(x) + half_window_x + 1, frame.shape[1])\n",
    "\n",
    "    window = frame[y_min:y_max, x_min:x_max]\n",
    "    if window.size == 0:\n",
    "        return x, y\n",
    "\n",
    "    # Calculate centroid using raw image moments\n",
    "    m = cv2.moments(window.astype(np.uint8))\n",
    "    if m['m00'] == 0:\n",
    "        return x, y\n",
    "    refined_x = x_min + (m['m10'] / m['m00'])\n",
    "    refined_y = y_min + (m['m01'] / m['m00'])\n",
    "    return refined_x, refined_y\n",
    "\n",
    "\n",
    "def local_maxima(img, min_distance):\n",
    "    \"\"\"\n",
    "    Find local maxima in an image, separated by at least min_distance.\n",
    "    Uses dilation + connected components.\n",
    "    \"\"\"\n",
    "    # Square structuring element sized to enforce min_distance separation\n",
    "    kernel = np.ones((2 * min_distance + 1, 2 * min_distance + 1), np.uint8)\n",
    "    dilated = cv2.dilate(img, kernel)\n",
    "    # Pixels equal to local dilation are local peaks\n",
    "    local_max_mask = (img == dilated)\n",
    "\n",
    "    # Suppress peaks too close to borders (cannot form a full neighbourhood)\n",
    "    local_max_mask[:min_distance, :] = False\n",
    "    local_max_mask[-min_distance:, :] = False\n",
    "    local_max_mask[:, :min_distance] = False\n",
    "    local_max_mask[:, -min_distance:] = False\n",
    "\n",
    "    # Label connected maxima regions and pick the brightest pixel per region\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(local_max_mask.astype(np.uint8))\n",
    "    coordinates = []\n",
    "\n",
    "    for label in range(1, num_labels):  # skip background\n",
    "        x, y, w, h, _ = stats[label]\n",
    "        sub_img = img[y:y + h, x:x + w]\n",
    "        _, _, _, maxLoc = cv2.minMaxLoc(sub_img)\n",
    "        global_y = y + maxLoc[1]\n",
    "        global_x = x + maxLoc[0]\n",
    "        coordinates.append((global_y, global_x))\n",
    "\n",
    "    if coordinates:\n",
    "        return np.array(coordinates)\n",
    "    else:\n",
    "        return np.empty((0, 2), dtype=int)\n",
    "\n",
    "\n",
    "def find_particles(frame, original_roi, min_distance, min_intensity,\n",
    "                   neighborhood_size, gaussian_blur_kernel_size,\n",
    "                   position_refinement_size, mass_grid_size):\n",
    "    \"\"\"\n",
    "    Detect particles in a frame:\n",
    "    - Blur image\n",
    "    - Find local maxima\n",
    "    - Filter by intensity threshold\n",
    "    - Refine positions\n",
    "    - Compute raw luminosity using integral image\n",
    "    \"\"\"\n",
    "    # Approximate sigma so the given kernel spans ~±3σ\n",
    "    sigma_x = gaussian_blur_kernel_size[0] / 6.0\n",
    "    sigma_y = gaussian_blur_kernel_size[1] / 6.0\n",
    "\n",
    "    # Blur to reduce noise and small-scale texture\n",
    "    blurred = cv2.GaussianBlur(frame, gaussian_blur_kernel_size, sigmaX=sigma_x, sigmaY=sigma_y)\n",
    "    # Local mean for intensity thresholding\n",
    "    averaged = cv2.boxFilter(frame, ddepth=-1, ksize=neighborhood_size, normalize=True)\n",
    "\n",
    "    # Detect local maxima candidates\n",
    "    coordinates = local_maxima(blurred, min_distance)\n",
    "    if coordinates.size == 0:\n",
    "        return pd.DataFrame(columns=['x', 'y', 'raw_luminosity', 'frame', 'tracker_type'])\n",
    "\n",
    "    # Filter by local mean intensity threshold\n",
    "    intensities = averaged[coordinates[:, 0], coordinates[:, 1]]\n",
    "    valid_coords = coordinates[intensities >= min_intensity]\n",
    "    if valid_coords.size == 0:\n",
    "        return pd.DataFrame(columns=['x', 'y', 'raw_luminosity', 'frame', 'tracker_type'])\n",
    "\n",
    "    # Refine positions (sub-pixel) around each valid coordinate\n",
    "    refined_positions = np.array([refine_centroid(blurred, x, y, window_size=position_refinement_size) for y, x in valid_coords])\n",
    "    x_positions = refined_positions[:, 0]\n",
    "    y_positions = refined_positions[:, 1]\n",
    "\n",
    "    # Compute luminosity using a summed-area table (integral image)\n",
    "    integral = cv2.integral(original_roi)\n",
    "    raw_luminosities = []\n",
    "    half_grid = mass_grid_size[0] // 2\n",
    "    for x, y in refined_positions:\n",
    "        x_int = int(round(x))\n",
    "        y_int = int(round(y))\n",
    "        # Window bounds inside the ROI for average intensity\n",
    "        y_min = max(y_int - half_grid, 0)\n",
    "        y_max = min(y_int + half_grid + 1, original_roi.shape[0])\n",
    "        x_min = max(x_int - half_grid, 0)\n",
    "        x_max = min(x_int + half_grid + 1, original_roi.shape[1])\n",
    "        # Fast sum via integral image\n",
    "        sum_window = integral[y_max, x_max] - integral[y_min, x_max] - integral[y_max, x_min] + integral[y_min, x_min]\n",
    "        area = (y_max - y_min) * (x_max - x_min)\n",
    "        raw_luminosities.append(sum_window / area if area > 0 else np.nan)\n",
    "\n",
    "    return pd.DataFrame({'x': x_positions, 'y': y_positions, 'raw_luminosity': raw_luminosities, 'frame': np.nan})\n",
    "\n",
    "\n",
    "def temporal_gaussian_blur(frames, kernel_size):\n",
    "    \"\"\"\n",
    "    Apply Gaussian blur across the temporal (time) dimension of a stack of frames.\n",
    "    \"\"\"\n",
    "    # Build a 1D Gaussian kernel over the time axis\n",
    "    sigma = kernel_size / 6\n",
    "    k = np.arange(kernel_size) - kernel_size // 2\n",
    "    kernel = np.exp(-0.5 * (k / sigma) ** 2)\n",
    "    kernel /= kernel.sum()\n",
    "\n",
    "    # Pad in time to avoid edge effects (replicate ends)\n",
    "    padded = np.pad(frames, ((kernel_size // 2, kernel_size // 2), (0, 0), (0, 0)), mode='edge')\n",
    "    blurred = np.empty_like(frames, dtype=np.float32)\n",
    "\n",
    "    # Convolve per-pixel along the temporal dimension\n",
    "    for i in range(frames.shape[0]):\n",
    "        blurred[i] = np.tensordot(kernel, padded[i:i + kernel_size], axes=(0, 0))\n",
    "    return blurred.astype(np.uint8)\n",
    "\n",
    "\n",
    "def read_video_frames(input_video_path, y_lower_limit, y_upper_limit, end_frame):\n",
    "    \"\"\"\n",
    "    Read frames from video up to end_frame.\n",
    "    Extract region of interest (ROI) between y_lower_limit and y_upper_limit.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    frames = []\n",
    "    frame_number = 0\n",
    "\n",
    "    while frame_number <= end_frame:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Convert to grayscale to simplify processing\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Crop to the vertical ROI; keep all columns\n",
    "        roi = gray[y_lower_limit:y_upper_limit, :]\n",
    "        frames.append(roi)\n",
    "        frame_number += 1\n",
    "\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "\n",
    "def process_frames(frames, y_lower_limit, end_frame,\n",
    "                   min_small_intensity, min_big_intensity,\n",
    "                   background_removal_small, background_removal_big,\n",
    "                   small_neighborhood_and_integration_size, big_neighborhood_and_integration_size,\n",
    "                   small_gaussian_blur_kernel_size, big_gaussian_blur_kernel_size,\n",
    "                   small_position_refinement_size, big_position_refinement_size,\n",
    "                   small_size, big_size,\n",
    "                   raw_luminosity_grid_size,\n",
    "                   temporal_gaussian_blur_kernel_size=None):\n",
    "    \"\"\"\n",
    "    Full pipeline for detecting small and big particles in each frame:\n",
    "    - Optionally apply temporal blur\n",
    "    - Optionally remove background\n",
    "    - Detect particles with different parameters for small/big\n",
    "    - Collect detections in DataFrame\n",
    "    \"\"\"\n",
    "    # Optional temporal smoothing to stabilise detections across frames\n",
    "    proc = temporal_gaussian_blur(frames, temporal_gaussian_blur_kernel_size) if temporal_gaussian_blur_kernel_size else frames\n",
    "    all_small, all_big = [], []\n",
    "\n",
    "    for i in range(frames.shape[0]):\n",
    "        roi = proc[i]\n",
    "        # When temporal blur is used, measure luminosity on original frame to avoid bias\n",
    "        roi_orig = frames[i] if temporal_gaussian_blur_kernel_size else roi\n",
    "\n",
    "        # Fit background once per frame (on a blurred version) if any removal is needed\n",
    "        coeff = fit_quadratic_surface(cv2.GaussianBlur(roi, small_gaussian_blur_kernel_size, 0),\n",
    "                                      small_neighborhood_and_integration_size) if (background_removal_small or background_removal_big) else None\n",
    "\n",
    "        # Apply background removal independently for small/big streams\n",
    "        roi_small = remove_background(roi, coeff) if background_removal_small and coeff is not None else roi.copy()\n",
    "        roi_big = remove_background(roi, coeff) if background_removal_big and coeff is not None else roi.copy()\n",
    "\n",
    "        # Minimum distance between peaks based on expected particle size\n",
    "        min_d_small = max(small_size) // 2\n",
    "        min_d_big = max(big_size) // 2\n",
    "\n",
    "        # Detect small particles\n",
    "        det_small = find_particles(roi_small, roi_orig, min_d_small, min_small_intensity,\n",
    "                                   small_neighborhood_and_integration_size, small_gaussian_blur_kernel_size,\n",
    "                                   small_position_refinement_size, raw_luminosity_grid_size)\n",
    "        if not det_small.empty:\n",
    "            # Shift back to full-frame coordinates on y-axis\n",
    "            det_small['y'] += y_lower_limit\n",
    "            det_small['frame'] = i\n",
    "            det_small['tracker_type'] = 'small'\n",
    "            all_small.append(det_small)\n",
    "\n",
    "        # Detect big particles\n",
    "        det_big = find_particles(roi_big, roi_orig, min_d_big, min_big_intensity,\n",
    "                                 big_neighborhood_and_integration_size, big_gaussian_blur_kernel_size,\n",
    "                                 big_position_refinement_size, raw_luminosity_grid_size)\n",
    "        if not det_big.empty:\n",
    "            det_big['y'] += y_lower_limit\n",
    "            det_big['frame'] = i\n",
    "            det_big['tracker_type'] = 'big'\n",
    "            all_big.append(det_big)\n",
    "\n",
    "    # Combine results; ensure columns exist if no detections\n",
    "    df_small = pd.concat(all_small, ignore_index=True) if all_small else pd.DataFrame(columns=['x', 'y', 'raw_luminosity', 'frame', 'tracker_type'])\n",
    "    df_big = pd.concat(all_big, ignore_index=True) if all_big else pd.DataFrame(columns=['x', 'y', 'raw_luminosity', 'frame', 'tracker_type'])\n",
    "    return pd.concat([df_small, df_big], ignore_index=True)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function:\n",
    "    - Read video frames\n",
    "    - Process frames to detect particles\n",
    "    - Save results to CSV\n",
    "    \"\"\"\n",
    "    input_video_path, output_folder, y_lower_limit, y_upper_limit, end_frame, params = get_config()\n",
    "\n",
    "    # Ensure output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Read video and extract ROI frames\n",
    "    frames = read_video_frames(input_video_path, y_lower_limit, y_upper_limit, end_frame)\n",
    "\n",
    "    # Run detection pipeline\n",
    "    detections = process_frames(frames, y_lower_limit, end_frame,\n",
    "                                params['min_small_intensity'], params['min_big_intensity'],\n",
    "                                params['background_removal_small'], params['background_removal_big'],\n",
    "                                params['small_neighborhood_and_integration_size'], params['big_neighborhood_and_integration_size'],\n",
    "                                params['small_gaussian_blur_kernel_size'], params['big_gaussian_blur_kernel_size'],\n",
    "                                params['small_position_refinement_size'], params['big_position_refinement_size'],\n",
    "                                params['small_size'], params['big_size'],\n",
    "                                params['raw_luminosity_grid_size'])\n",
    "\n",
    "    # Save results for downstream linking\n",
    "    detections['video'] = os.path.basename(input_video_path)\n",
    "    detections.to_csv(os.path.join(output_folder, 'particle_detections.csv'), index=False)\n",
    "    print(len(detections), \"rows exported for particle_detections.csv\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track Linking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from scipy.spatial import cKDTree\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_config():\n",
    "    \"\"\"\n",
    "    Define I/O and all tracking hyperparameters for forward and reverse linking.\n",
    "    \"\"\"\n",
    "    base = \"/Users/Ricardo/Desktop/Y4 Lab code/Work 0.3K\"\n",
    "\n",
    "    # Forward-pass constraints (when linking in ascending frame order)\n",
    "    fwd_params = {\n",
    "        \"memory\": 0,  # how many consecutive frames a track can be unmatched before deletion\n",
    "        # Speed thresholds (pixels/frame) that define low/medium/high regimes\n",
    "        \"slow_max_speed\": 6, \"medium_max_speed\": 12, \"high_max_speed\": 65,\n",
    "        # Allowed change in direction (radians) for each regime\n",
    "        \"low_direction_change_limits\": {\"lower\": -np.pi, \"upper\": np.pi},\n",
    "        \"medium_direction_change_limits\": {\"lower\": -0.4 * np.pi, \"upper\": 0.4 * np.pi},\n",
    "        \"high_direction_change_limits\": {\"lower\": -0.15 * np.pi, \"upper\": 0.15 * np.pi},\n",
    "        # Allowed change in speed (Δ pixels/frame) for each regime\n",
    "        \"low_speed_change_limits\": {\"lower\": -30, \"upper\": 50},\n",
    "        \"medium_speed_change_limits\": {\"lower\": -40, \"upper\": 55},\n",
    "        \"high_speed_change_limits\": {\"lower\": -50, \"upper\": 60},\n",
    "        # Distance threshold (pixels) to look back in a track’s history for a “previous” point\n",
    "        \"directional_threshold\": 12\n",
    "    }\n",
    "\n",
    "    # Reverse-pass constraints (when linking in descending frame order)\n",
    "    # Direction limits are symmetric; speed-change limits are mirrored\n",
    "    rev_params = {\n",
    "        \"memory\": 0,\n",
    "        \"slow_max_speed\": 6, \"medium_max_speed\": 12, \"high_max_speed\": 65,\n",
    "        \"low_direction_change_limits\": {\"lower\": -np.pi, \"upper\": np.pi},\n",
    "        \"medium_direction_change_limits\": {\"lower\": -0.4 * np.pi, \"upper\": 0.4 * np.pi},\n",
    "        \"high_direction_change_limits\": {\"lower\": -0.15 * np.pi, \"upper\": 0.15 * np.pi},\n",
    "        \"low_speed_change_limits\": {\"lower\": -50, \"upper\": 30},\n",
    "        \"medium_speed_change_limits\": {\"lower\": -55, \"upper\": 40},\n",
    "        \"high_speed_change_limits\": {\"lower\": -60, \"upper\": 50},\n",
    "        \"directional_threshold\": 12\n",
    "    }\n",
    "\n",
    "    end_frame = 600   # not used directly here, but returned for potential future use\n",
    "    min_links = 10    # minimum detections per track to keep after filtering\n",
    "    return (None, None, None, fwd_params, rev_params, end_frame, min_links)\n",
    "\n",
    "\n",
    "class MemoryManager:\n",
    "    \"\"\"\n",
    "    Tracks currently-active particle tracks and basic per-track stats.\n",
    "    \"\"\"\n",
    "    def __init__(self, memory):\n",
    "        self.memory = memory               # max tolerated consecutive missed frames\n",
    "        self.active = {}                   # active tracks: id -> state dict\n",
    "        self.length = {}                   # total assigned detections per track id\n",
    "\n",
    "    def add(self, ids, positions):\n",
    "        \"\"\"\n",
    "        Start new tracks with given ids at given positions.\n",
    "        \"\"\"\n",
    "        for p in ids:\n",
    "            self.active[p] = {\n",
    "                \"position\": positions[p],      # last known (x, y)\n",
    "                \"history\": [positions[p]],     # full position history (list of (x, y))\n",
    "                \"frames_lost\": 0,              # # of consecutive misses\n",
    "                \"previous_speed\": 0,           # last observed speed (pixels/frame)\n",
    "                \"speed_mode\": \"low\"            # last regime: 'low'|'medium'|'high'\n",
    "            }\n",
    "            self.length[p] = 1\n",
    "\n",
    "    def update(self, ids, new_positions):\n",
    "        \"\"\"\n",
    "        Update existing tracks (append to history and bump length counter).\n",
    "        \"\"\"\n",
    "        for p in ids:\n",
    "            if p in self.active:\n",
    "                self.active[p][\"history\"].append(new_positions[p])\n",
    "                self.active[p][\"position\"] = new_positions[p]\n",
    "                self.length[p] += 1\n",
    "\n",
    "\n",
    "class Statistics:\n",
    "    \"\"\"\n",
    "    Collect diagnostics on rejected candidate links (angles and speed changes)\n",
    "    and total distance travelled per regime.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.dir_stats = {\"low\": [], \"medium\": [], \"high\": []}     # rejected direction-change values\n",
    "        self.speed_stats = {\"low\": [], \"medium\": [], \"high\": []}   # rejected speed-change values\n",
    "        self.distances = {\"low\": 0, \"medium\": 0, \"high\": 0}        # accepted path length per regime\n",
    "\n",
    "    def update_dir(self, mode, angle, params):\n",
    "        self.dir_stats[mode].append(angle)\n",
    "\n",
    "    def update_speed(self, mode, speed_change, params):\n",
    "        self.speed_stats[mode].append(speed_change)\n",
    "\n",
    "    def add_distance(self, mode, distance):\n",
    "        self.distances[mode] += distance\n",
    "\n",
    "\n",
    "def calc_angle_jit(prev, cur, nw):\n",
    "    \"\"\"\n",
    "    Compute signed turn angle between vectors (prev->cur) and (cur->nw).\n",
    "    Returns angle in radians in [-pi, pi]. If any segment has zero length, returns 0.\n",
    "    \"\"\"\n",
    "    m1 = cur - prev\n",
    "    m2 = nw - cur\n",
    "    n1 = np.sqrt(m1[0] * m1[0] + m1[1] * m1[1])\n",
    "    n2 = np.sqrt(m2[0] * m2[0] + m2[1] * m2[1])\n",
    "    if n1 == 0 or n2 == 0:\n",
    "        return 0.0\n",
    "    dp = (m1[0] * m2[0] + m1[1] * m2[1]) / (n1 * n2)\n",
    "    dp = min(max(dp, -1.0), 1.0)  # numerical clamp for arccos domain\n",
    "    ang = np.arccos(dp)\n",
    "    # Determine sign using 2D cross product (z-component)\n",
    "    if m1[0] * m2[1] - m1[1] * m2[0] < 0:\n",
    "        ang = -ang\n",
    "    return ang\n",
    "\n",
    "\n",
    "def calc_angle(prev, cur, nw):\n",
    "    \"\"\"\n",
    "    Wrapper that handles None 'prev' point and ensures float inputs.\n",
    "    \"\"\"\n",
    "    if prev is None:\n",
    "        return 0.0\n",
    "    return calc_angle_jit(\n",
    "        np.asarray(prev, dtype=np.float64),\n",
    "        np.asarray(cur, dtype=np.float64),\n",
    "        np.asarray(nw, dtype=np.float64)\n",
    "    )\n",
    "\n",
    "\n",
    "def find_prev(hist, cur, thresh):\n",
    "    \"\"\"\n",
    "    Walk history backwards to find the latest point far enough from 'cur'\n",
    "    (distance > thresh). Helps stabilise direction-change estimation.\n",
    "    \"\"\"\n",
    "    for prev in reversed(hist[:-1]):\n",
    "        if np.linalg.norm(cur - prev) > thresh:\n",
    "            return prev\n",
    "    return None\n",
    "\n",
    "\n",
    "def custom_link(dets, params, stats, asc=True):\n",
    "    \"\"\"\n",
    "    Greedy frame-by-frame linker with physics-inspired constraints.\n",
    "    - dets: DataFrame with columns ['frame','x','y']\n",
    "    - params: hyperparameters dict (see get_config)\n",
    "    - stats: Statistics object to collect diagnostics\n",
    "    - asc: True for forward pass (increasing frame); False for reverse\n",
    "    Returns: (linked DataFrame, count_rank1_matches, count_rank2_matches)\n",
    "    \"\"\"\n",
    "    mem = params[\"memory\"]\n",
    "    max_dist = params[\"high_max_speed\"]     # KD-tree search radius\n",
    "    thresh = params[\"directional_threshold\"]\n",
    "    pid = 0                                 # next new track id\n",
    "\n",
    "    # Sort detections by frame in chosen direction\n",
    "    dets = dets.sort_values(\"frame\", ascending=asc).reset_index(drop=True)\n",
    "    dets[\"particle\"] = np.nan\n",
    "\n",
    "    mm = MemoryManager(mem)\n",
    "    l1 = l2 = 0  # number of first-choice and second-choice links accepted\n",
    "\n",
    "    for f, fd in dets.groupby(\"frame\"):\n",
    "        pos = fd[[\"x\", \"y\"]].values\n",
    "        idxs = fd.index.values\n",
    "\n",
    "        # If no active tracks, start new ones for all detections\n",
    "        if not mm.active:\n",
    "            new_ids = list(range(pid, pid + len(fd)))\n",
    "            new_pos = {p: pos[i] for i, p in enumerate(new_ids)}\n",
    "            mm.add(new_ids, new_pos)\n",
    "            dets.loc[idxs, \"particle\"] = new_ids\n",
    "            pid += len(fd)\n",
    "            continue\n",
    "\n",
    "        # Rank active ids by their current length (prefer longer, more stable tracks)\n",
    "        act_ids = sorted(mm.active.keys(), key=lambda p: mm.length[p], reverse=True)\n",
    "        active = mm.active\n",
    "\n",
    "        # If still empty (paranoia), spawn all as new\n",
    "        if not act_ids:\n",
    "            new_ids = list(range(pid, pid + len(fd)))\n",
    "            new_pos = {p: pos[i] for i, p in enumerate(new_ids)}\n",
    "            mm.add(new_ids, new_pos)\n",
    "            dets.loc[idxs, \"particle\"] = new_ids\n",
    "            pid += len(fd)\n",
    "            continue\n",
    "\n",
    "        # Build KD-tree over last positions of active tracks to find candidate links\n",
    "        act_pos = np.array([active[p][\"position\"] for p in act_ids])\n",
    "        tree = cKDTree(act_pos)\n",
    "        # Query up to 2 nearest active tracks for each detection (within max_dist)\n",
    "        dists, a_idxs = tree.query(pos, k=2, distance_upper_bound=max_dist)\n",
    "\n",
    "        # Prepare all possible (track, detection) pairings with angle & distance\n",
    "        poss_list = []\n",
    "        for i in range(len(pos)):\n",
    "            for k in range(2):  # consider 1st and 2nd nearest\n",
    "                if a_idxs[i, k] >= len(act_ids) or dists[i, k] == np.inf:\n",
    "                    continue\n",
    "                aid = act_ids[a_idxs[i, k]]\n",
    "                part = active[aid]\n",
    "                cur_pos = part[\"position\"]\n",
    "                prev_pt = find_prev(part[\"history\"], cur_pos, thresh)\n",
    "                angle = calc_angle(prev_pt, cur_pos, pos[i])\n",
    "                poss_list.append((aid, i, idxs[i], angle, dists[i, k], k+1))  # rank=k+1\n",
    "\n",
    "        # Sort candidates:\n",
    "        #   1) longer tracks first\n",
    "        #   2) smaller |angle| (straighter continuation)\n",
    "        #   3) smaller spatial distance\n",
    "        poss_list.sort(key=lambda x: (-mm.length[x[0]], abs(x[3]), x[4]))\n",
    "\n",
    "        used_a = set()  # already used active track ids\n",
    "        used_d = set()  # already used detection indices\n",
    "        fm = []         # accepted matches: (aid, det_idx, rank)\n",
    "\n",
    "        for aid, di, dii, angle, dist_val, rank in poss_list:\n",
    "            if aid in used_a or di in used_d:\n",
    "                continue\n",
    "\n",
    "            part = active.get(aid)\n",
    "            if part is None:\n",
    "                continue\n",
    "\n",
    "            # Compute angle and speed using most recent two points\n",
    "            prev_pt = part[\"history\"][-2] if len(part[\"history\"]) >= 2 else None\n",
    "            angle = calc_angle(prev_pt, part[\"position\"], pos[di])\n",
    "            disp = pos[di] - part[\"position\"]\n",
    "            spd = np.linalg.norm(disp)\n",
    "            spd_ch = spd - part[\"previous_speed\"]\n",
    "\n",
    "            # Determine current speed regime of candidate\n",
    "            cm = \"low\" if spd <= params[\"slow_max_speed\"] else (\"medium\" if spd <= params[\"medium_max_speed\"] else \"high\")\n",
    "            pm = part[\"speed_mode\"]  # previous regime\n",
    "\n",
    "            # Compose cumulative limits across regime transition path\n",
    "            modes = [\"low\", \"medium\", \"high\"]\n",
    "            pi, ci = modes.index(pm), modes.index(cm)\n",
    "            seq = modes[pi:ci+1] if pi <= ci else modes[ci:pi+1]\n",
    "\n",
    "            cs_lim = {\"lower\": -np.inf, \"upper\": np.inf}  # cumulative speed-change limits\n",
    "            cd_lim = {\"lower\": -np.inf, \"upper\": np.inf}  # cumulative direction-change limits\n",
    "            for m in seq:\n",
    "                sp_lim = params[f\"{m}_speed_change_limits\"]\n",
    "                d_lim = params[f\"{m}_direction_change_limits\"]\n",
    "                cs_lim[\"lower\"] = max(cs_lim[\"lower\"], sp_lim[\"lower\"])\n",
    "                cs_lim[\"upper\"] = min(cs_lim[\"upper\"], sp_lim[\"upper\"])\n",
    "                cd_lim[\"lower\"] = max(cd_lim[\"lower\"], d_lim[\"lower\"])\n",
    "                cd_lim[\"upper\"] = min(cd_lim[\"upper\"], d_lim[\"upper\"])\n",
    "\n",
    "            # Apply constraints; if violated, keep diagnostics and possibly drop track\n",
    "            rej = False\n",
    "            if not (cd_lim[\"lower\"] <= angle <= cd_lim[\"upper\"]):\n",
    "                stats.update_dir(cm, angle, params)\n",
    "                rej = True\n",
    "            if not (cs_lim[\"lower\"] <= spd_ch <= cs_lim[\"upper\"]):\n",
    "                stats.update_speed(cm, spd_ch, params)\n",
    "                rej = True\n",
    "            if rej:\n",
    "                part[\"frames_lost\"] += 1\n",
    "                if part[\"frames_lost\"] > params[\"memory\"]:\n",
    "                    # Forget track if memory exceeded\n",
    "                    del active[aid]\n",
    "                    del mm.length[aid]\n",
    "                continue\n",
    "\n",
    "            # Accept match: assign detection to track\n",
    "            dets.at[dii, \"particle\"] = aid\n",
    "            fm.append((aid, di, rank))\n",
    "            used_a.add(aid)\n",
    "            used_d.add(di)\n",
    "            l1 += (rank == 1)\n",
    "            l2 += (rank == 2)\n",
    "\n",
    "        # Commit accepted matches: update positions & per-track speed regime\n",
    "        new_pos = {}\n",
    "        mids = []\n",
    "        for aid, di, _ in fm:\n",
    "            new_pos[aid] = pos[di]\n",
    "            spd = np.linalg.norm(pos[di] - active[aid][\"position\"])\n",
    "            sm_val = \"low\" if spd <= params[\"slow_max_speed\"] else (\"medium\" if spd <= params[\"medium_max_speed\"] else \"high\")\n",
    "            active[aid][\"speed_mode\"] = sm_val\n",
    "            active[aid][\"previous_speed\"] = spd\n",
    "            stats.add_distance(sm_val, spd)\n",
    "            mids.append(aid)\n",
    "        mm.update(mids, new_pos)\n",
    "\n",
    "        # Any detections not matched start new tracks\n",
    "        un = set(range(len(fd))) - used_d\n",
    "        if un:\n",
    "            new_ids = list(range(pid, pid + len(un)))\n",
    "            new_pos = {p: pos[i] for p, i in zip(new_ids, un)}\n",
    "            mm.add(new_ids, new_pos)\n",
    "            for p, i in zip(new_ids, un):\n",
    "                dets.at[idxs[i], \"particle\"] = p\n",
    "            pid += len(un)\n",
    "\n",
    "    # Ensure nullable integer dtype for particle ids\n",
    "    dets[\"particle\"] = dets[\"particle\"].astype(\"Int64\")\n",
    "\n",
    "    # Return frame order consistent with pass direction\n",
    "    return (dets.sort_values(\"frame\").reset_index(drop=True) if not asc else dets, l1, l2)\n",
    "\n",
    "\n",
    "def process_tracker_type(args):\n",
    "    \"\"\"\n",
    "    Run forward and reverse linking for a given tracker_type subset.\n",
    "    Adds metadata columns and returns both DataFrames.\n",
    "    \"\"\"\n",
    "    t, sub, fwd_params, rev_params = args\n",
    "    stats_f = Statistics()\n",
    "    stats_r = Statistics()\n",
    "\n",
    "    # Forward pass\n",
    "    lf, _, _ = custom_link(sub.copy(), fwd_params, stats_f, asc=True)\n",
    "    lf[\"link_direction\"] = \"forward\"\n",
    "    lf[\"tracker_type\"] = t + \"_forward\"\n",
    "    lf[\"unique_id\"] = lf[\"particle\"].apply(lambda x: f\"{t}_forward_{int(x)}\")\n",
    "\n",
    "    # Reverse pass\n",
    "    lr, _, _ = custom_link(sub.copy(), rev_params, stats_r, asc=False)\n",
    "    lr[\"link_direction\"] = \"reverse\"\n",
    "    lr[\"tracker_type\"] = t + \"_reverse\"\n",
    "    lr[\"unique_id\"] = lr[\"particle\"].apply(lambda x: f\"{t}_reverse_{int(x)}\")\n",
    "\n",
    "    return lf, lr\n",
    "\n",
    "\n",
    "def find_overlaps(df, dt, mcf):\n",
    "    \"\"\"\n",
    "    Identify overlapping tracks (close in space within 'dt' pixels) that co-exist\n",
    "    for at least 'mcf' consecutive frames. Returns:\n",
    "      - osm: dict[(idA,idB)] -> list of (start_frame, end_frame) segments\n",
    "      - tl: dict unique_id -> total length (# detections) of each track\n",
    "    \"\"\"\n",
    "    # Group detections per frame for efficient per-frame proximity queries\n",
    "    frame_groups = {f: group for f, group in df.groupby(\"frame\")}\n",
    "    # Track lengths\n",
    "    tl = df.groupby(\"unique_id\").size().to_dict()\n",
    "\n",
    "    # Candidate overlaps (per pair -> list of frames where distance < dt)\n",
    "    od = defaultdict(list)\n",
    "    for f, group in frame_groups.items():\n",
    "        pos = group[[\"x\", \"y\"]].values\n",
    "        parts = group[\"unique_id\"].values\n",
    "        if len(pos) == 0:\n",
    "            continue\n",
    "        tree = cKDTree(pos)\n",
    "        for i, j in tree.query_pairs(dt):\n",
    "            od[tuple(sorted((parts[i], parts[j])))] .append(f)\n",
    "\n",
    "    # Convert scattered frames into contiguous segments of length >= mcf\n",
    "    osm = {}\n",
    "    for c, fs in od.items():\n",
    "        fs = sorted(fs)\n",
    "        seg = []\n",
    "        s = fs[0]\n",
    "        p = fs[0]\n",
    "        for f in fs[1:]:\n",
    "            if f == p + 1:\n",
    "                p = f\n",
    "            else:\n",
    "                if p - s + 1 >= mcf:\n",
    "                    seg.append((s, p))\n",
    "                s = f\n",
    "                p = f\n",
    "        if p - s + 1 >= mcf:\n",
    "            seg.append((s, p))\n",
    "        if seg:\n",
    "            osm[c] = seg\n",
    "    return osm, tl\n",
    "\n",
    "\n",
    "def filter_tracks(df, osm, tl):\n",
    "    \"\"\"\n",
    "    Remove the shorter member of overlapping track pairs over their overlapping\n",
    "    segments, keeping the longer one intact.\n",
    "    \"\"\"\n",
    "    rem = set()\n",
    "    for cl, segs in osm.items():\n",
    "        # pick the longest track in the conflicted pair\n",
    "        cll = {p: tl[p] for p in cl}\n",
    "        lp = max(cll, key=cll.get)         # keep this one\n",
    "        sp = [p for p in cl if p != lp]    # candidates to remove within overlap\n",
    "        # Remove only the overlapping portions of the shorter track(s)\n",
    "        for s, e in segs:\n",
    "            for p in sp:\n",
    "                rem.update(df[(df[\"unique_id\"] == p) & (df[\"frame\"] >= s) & (df[\"frame\"] <= e)].index.tolist())\n",
    "    return df.drop(rem).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Entry point:\n",
    "      1) Load detections\n",
    "      2) Track separately per original tracker_type (e.g., 'small'/'big')\n",
    "      3) Run forward and reverse linkers; combine\n",
    "      4) Detect spatial overlaps and filter shorter duplicates\n",
    "      5) Keep only tracks with >= min_links detections\n",
    "      6) Save CSVs\n",
    "    \"\"\"\n",
    "    (_, _, _, fwd_params, rev_params, end_frame, min_links) = get_config()\n",
    "\n",
    "    # List of detection CSVs to process\n",
    "    det_files = [\"/Users/Ricardo/Desktop/Y4 Lab code/Work 0.3K/particle_detections.csv\"]\n",
    "\n",
    "    for det_file in det_files:\n",
    "        # Only required columns here; original 'tracker_type' comes from detection stage\n",
    "        det = pd.read_csv(det_file, usecols=[\"frame\", \"x\", \"y\", \"tracker_type\"])\n",
    "\n",
    "        # Track each detection subtype independently (e.g., 'small' and 'big')\n",
    "        unique_types = det[\"tracker_type\"].unique()\n",
    "        res = []\n",
    "        for t in unique_types:\n",
    "            sub = det[det[\"tracker_type\"] == t].copy()\n",
    "            lf, lr = process_tracker_type((t, sub, fwd_params, rev_params))\n",
    "            res.extend([lf, lr])\n",
    "\n",
    "        # Combine forward+reverse passes and export raw tracks\n",
    "        comb = pd.concat(res, ignore_index=True)\n",
    "        out_track = os.path.join(os.path.dirname(det_file), \"particle_tracks_v1.csv\")\n",
    "        out_filt  = os.path.join(os.path.dirname(det_file), \"filtered_particle_tracks_v1.csv\")\n",
    "        comb.to_csv(out_track, index=False)\n",
    "\n",
    "        # Overlap filtering parameters:\n",
    "        dt = 3   # spatial proximity for overlap (pixels)\n",
    "        mcf = 2  # minimum consecutive frames to consider as real overlap\n",
    "\n",
    "        # Find overlaps and track lengths, then filter\n",
    "        osm, tl = find_overlaps(comb, dt, mcf)\n",
    "        filt = filter_tracks(comb, osm, tl)\n",
    "\n",
    "        # Drop short tracks (keep only those with at least 'min_links' detections)\n",
    "        cnt = filt[\"unique_id\"].value_counts()\n",
    "        filt = filt[filt[\"unique_id\"].isin(cnt[cnt >= min_links].index)].reset_index(drop=True)\n",
    "\n",
    "        # Save filtered result\n",
    "        filt.to_csv(out_filt, index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_forward: Processed 14889 candidates; Total distance cost: 231078.434, Total angle cost: 13452.558, Total lum cost: 22525.845; Total skipped (max_lum_diff): 1134; Number of tracks: 2319; Number of links: 5969\n",
      "small_reverse: Processed 14809 candidates; Total distance cost: 228085.767, Total angle cost: 12648.689, Total lum cost: 22447.516; Total skipped (max_lum_diff): 1141; Number of tracks: 2583; Number of links: 5705\n",
      "big_forward: Processed 13773 candidates; Total distance cost: 219520.097, Total angle cost: 12261.695, Total lum cost: 21042.776; Total skipped (max_lum_diff): 929; Number of tracks: 2088; Number of links: 5529\n",
      "big_reverse: Processed 13697 candidates; Total distance cost: 218273.187, Total angle cost: 11548.801, Total lum cost: 21001.235; Total skipped (max_lum_diff): 938; Number of tracks: 2330; Number of links: 5287\n",
      "Combined Tracker: Total tracks: 9320; Total links: 22490\n",
      "Filtered Tracker: Total tracks: 123; Total links: 2752\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from scipy.spatial import cKDTree\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_config():\n",
    "    \"\"\"\n",
    "    Define tracking hyperparameters (forward and reverse passes) and global settings.\n",
    "    \"\"\"\n",
    "    base = \"/Users/Ricardo/Desktop/Y4 Lab code/Work 0.3K\"\n",
    "\n",
    "    # Forward-pass parameters (ascending frame order)\n",
    "    fwd_params = {\n",
    "        \"memory\": 0,  # how many consecutive frames a track can be unmatched before being dropped\n",
    "\n",
    "        # Speed thresholds (pixels/frame) defining regimes\n",
    "        \"slow_max_speed\": 6,\n",
    "        \"medium_max_speed\": 12,\n",
    "        \"high_max_speed\": 65,\n",
    "\n",
    "        # Allowed direction change (radians) per regime\n",
    "        \"low_direction_change_limits\": {\"lower\": -np.pi, \"upper\": np.pi},\n",
    "        \"medium_direction_change_limits\": {\"lower\": -0.4 * np.pi, \"upper\": 0.4 * np.pi},\n",
    "        \"high_direction_change_limits\": {\"lower\": -0.15 * np.pi, \"upper\": 0.15 * np.pi},\n",
    "\n",
    "        # Allowed speed change (Δ pixels/frame) per regime\n",
    "        \"low_speed_change_limits\": {\"lower\": -30, \"upper\": 50},\n",
    "        \"medium_speed_change_limits\": {\"lower\": -40, \"upper\": 55},\n",
    "        \"high_speed_change_limits\": {\"lower\": -50, \"upper\": 60},\n",
    "\n",
    "        # Multi-objective matching weights & constraints\n",
    "        \"w_distance\": 1.0,   # weight for spatial distance cost\n",
    "        \"w_angle\": 1.0,      # weight for turning angle cost\n",
    "        \"w_lum\": 0.1,        # weight for luminosity difference cost\n",
    "        \"max_lum_diff\": 100  # hard gate on allowed luminosity difference\n",
    "    }\n",
    "\n",
    "    # Reverse-pass parameters (descending frame order)\n",
    "    # Same geometry limits; speed-change limits are mirrored\n",
    "    rev_params = {\n",
    "        \"memory\": 0,\n",
    "        \"slow_max_speed\": 6,\n",
    "        \"medium_max_speed\": 12,\n",
    "        \"high_max_speed\": 65,\n",
    "        \"low_direction_change_limits\": {\"lower\": -np.pi, \"upper\": np.pi},\n",
    "        \"medium_direction_change_limits\": {\"lower\": -0.4 * np.pi, \"upper\": 0.4 * np.pi},\n",
    "        \"high_direction_change_limits\": {\"lower\": -0.15 * np.pi, \"upper\": 0.15 * np.pi},\n",
    "        \"low_speed_change_limits\": {\"lower\": -50, \"upper\": 30},\n",
    "        \"medium_speed_change_limits\": {\"lower\": -55, \"upper\": 40},\n",
    "        \"high_speed_change_limits\": {\"lower\": -60, \"upper\": 50},\n",
    "        \"w_distance\": 1.0,\n",
    "        \"w_angle\": 1.0,\n",
    "        \"w_lum\": 0.1,\n",
    "        \"max_lum_diff\": 100\n",
    "    }\n",
    "\n",
    "    end_frame = 600  # returned for potential future use (not consumed here)\n",
    "    min_links = 10   # minimum detections per track to retain after filtering\n",
    "    return (None, None, None, fwd_params, rev_params, end_frame, min_links)\n",
    "\n",
    "\n",
    "class MemoryManager:\n",
    "    \"\"\"\n",
    "    Keeps state for active tracks and their histories.\n",
    "    \"\"\"\n",
    "    def __init__(self, memory):\n",
    "        self.memory = memory              # tolerated missed frames\n",
    "        self.active = {}                  # track_id -> state dict\n",
    "        self.length = {}                  # track_id -> count of assigned detections\n",
    "\n",
    "    def add(self, ids, positions, luminosities):\n",
    "        \"\"\"\n",
    "        Start new tracks with given ids, initial positions and luminosities.\n",
    "        \"\"\"\n",
    "        for i, p in enumerate(ids):\n",
    "            self.active[p] = {\n",
    "                \"position\": positions[i],         # last position (x, y)\n",
    "                \"history\": [positions[i]],        # full trajectory (list of (x, y))\n",
    "                \"luminosity\": luminosities[i],    # last luminosity\n",
    "                \"lum_history\": [luminosities[i]], # luminosity history\n",
    "                \"frames_lost\": 0,                 # consecutive unmatched frames\n",
    "                \"previous_speed\": 0,              # last speed (pixels/frame)\n",
    "                \"speed_mode\": \"low\"               # last regime: 'low'|'medium'|'high'\n",
    "            }\n",
    "            self.length[p] = 1\n",
    "\n",
    "    def update(self, ids, new_positions, new_luminosities):\n",
    "        \"\"\"\n",
    "        Update existing tracks that were matched this frame.\n",
    "        \"\"\"\n",
    "        for p in ids:\n",
    "            if p in self.active:\n",
    "                self.active[p][\"history\"].append(new_positions[p])\n",
    "                self.active[p][\"position\"] = new_positions[p]\n",
    "                self.active[p][\"lum_history\"].append(new_luminosities[p])\n",
    "                self.active[p][\"luminosity\"] = new_luminosities[p]\n",
    "                self.length[p] += 1\n",
    "\n",
    "\n",
    "class Statistics:\n",
    "    \"\"\"\n",
    "    Collect diagnostics (for debugging/tuning) and cumulative distances per regime.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.dir_stats = {\"low\": [], \"medium\": [], \"high\": []}     # rejected direction changes\n",
    "        self.speed_stats = {\"low\": [], \"medium\": [], \"high\": []}   # rejected speed changes\n",
    "        self.distances = {\"low\": 0, \"medium\": 0, \"high\": 0}        # accepted distances\n",
    "\n",
    "    def update_dir(self, mode, angle, params):\n",
    "        self.dir_stats[mode].append(angle)\n",
    "\n",
    "    def update_speed(self, mode, speed_change, params):\n",
    "        self.speed_stats[mode].append(speed_change)\n",
    "\n",
    "    def add_distance(self, mode, distance):\n",
    "        self.distances[mode] += distance\n",
    "\n",
    "\n",
    "def calc_angle_jit(prev, cur, nw):\n",
    "    \"\"\"\n",
    "    Compute signed turning angle between (prev->cur) and (cur->nw).\n",
    "    Returns radians in [-pi, pi]. If a segment is degenerate, returns 0.\n",
    "    \"\"\"\n",
    "    m1 = cur - prev\n",
    "    m2 = nw - cur\n",
    "    n1 = np.sqrt(m1[0]**2 + m1[1]**2)\n",
    "    n2 = np.sqrt(m2[0]**2 + m2[1]**2)\n",
    "    if n1 == 0 or n2 == 0:\n",
    "        return 0.0\n",
    "    dp = (m1[0]*m2[0] + m1[1]*m2[1]) / (n1*n2)\n",
    "    dp = min(max(dp, -1.0), 1.0)  # numerical clamp\n",
    "    ang = np.arccos(dp)\n",
    "    # Use 2D cross product sign for direction\n",
    "    if m1[0]*m2[1] - m1[1]*m2[0] < 0:\n",
    "        ang = -ang\n",
    "    return ang\n",
    "\n",
    "\n",
    "def calc_angle(prev, cur, nw):\n",
    "    \"\"\"\n",
    "    Safe wrapper: handle None and ensure float arrays.\n",
    "    \"\"\"\n",
    "    if prev is None:\n",
    "        return 0.0\n",
    "    return calc_angle_jit(np.asarray(prev, dtype=np.float64),\n",
    "                          np.asarray(cur,  dtype=np.float64),\n",
    "                          np.asarray(nw,   dtype=np.float64))\n",
    "\n",
    "\n",
    "def find_prev(hist, cur, thresh):\n",
    "    \"\"\"\n",
    "    Walk back along a track’s history to find the most recent point\n",
    "    sufficiently far from 'cur' (distance > thresh). Stabilises angle.\n",
    "    \"\"\"\n",
    "    for prev in reversed(hist[:-1]):\n",
    "        if np.linalg.norm(cur - prev) > thresh:\n",
    "            return prev\n",
    "    return None\n",
    "\n",
    "\n",
    "def custom_link(dets, params, stats, asc=True, tracker_name=\"\"):\n",
    "    \"\"\"\n",
    "    Greedy frame-by-frame linker with multi-objective matching:\n",
    "      - distance (nearest neighbours via KD-tree)\n",
    "      - turning angle (trajectory smoothness)\n",
    "      - luminosity similarity (appearance)\n",
    "    Candidate pairs outside geometry/luminosity gates are skipped.\n",
    "    Accepted pairs are then tested against regime-specific direction/speed-change limits.\n",
    "    \"\"\"\n",
    "    mem = params[\"memory\"]\n",
    "    max_dist = params[\"high_max_speed\"]   # KD-tree search radius (pixels)\n",
    "\n",
    "    # Cost weights & hard gate on luminosity\n",
    "    w_distance = params[\"w_distance\"]\n",
    "    w_angle = params[\"w_angle\"]\n",
    "    w_lum = params[\"w_lum\"]\n",
    "    max_lum_diff = params[\"max_lum_diff\"]\n",
    "\n",
    "    pid = 0  # next new track id\n",
    "\n",
    "    # Sort detections by frame (ascending for forward, descending for reverse)\n",
    "    dets = dets.sort_values(\"frame\", ascending=asc).reset_index(drop=True)\n",
    "    dets[\"particle\"] = np.nan\n",
    "\n",
    "    mm = MemoryManager(mem)\n",
    "\n",
    "    # Counters for diagnostics\n",
    "    l1 = l2 = 0                            # accepted first-/second-nearest links\n",
    "    overall_candidate_count = 0            # number of evaluated candidates\n",
    "    overall_distance_cost = 0.0\n",
    "    overall_angle_cost = 0.0\n",
    "    overall_lum_cost = 0.0\n",
    "    overall_skip_count = 0                 # luminosity gate rejections\n",
    "\n",
    "    # Process one frame at a time\n",
    "    for f, fd in dets.groupby(\"frame\"):\n",
    "        # Per-frame diagnostics\n",
    "        frame_distance_cost = 0.0\n",
    "        frame_angle_cost = 0.0\n",
    "        frame_lum_cost = 0.0\n",
    "        frame_candidate_count = 0\n",
    "        frame_skip_count = 0\n",
    "\n",
    "        # Current detections: positions and luminosities\n",
    "        pos = fd[[\"x\", \"y\"]].values\n",
    "        lum_arr = fd[\"raw_luminosity\"].values\n",
    "        idxs = fd.index.values\n",
    "\n",
    "        # If no active tracks, spawn new ones for every detection\n",
    "        if not mm.active:\n",
    "            new_ids = list(range(pid, pid + len(fd)))\n",
    "            mm.add(new_ids, list(pos), list(lum_arr))\n",
    "            dets.loc[idxs, \"particle\"] = new_ids\n",
    "            pid += len(fd)\n",
    "            continue\n",
    "\n",
    "        # Rank active tracks by length (prefer longer, more stable tracks)\n",
    "        act_ids = sorted(mm.active.keys(), key=lambda p: mm.length[p], reverse=True)\n",
    "        active = mm.active\n",
    "\n",
    "        # If empty after sorting (edge case), spawn all as new\n",
    "        if not act_ids:\n",
    "            new_ids = list(range(pid, pid + len(fd)))\n",
    "            mm.add(new_ids, list(pos), list(lum_arr))\n",
    "            dets.loc[idxs, \"particle\"] = new_ids\n",
    "            pid += len(fd)\n",
    "            continue\n",
    "\n",
    "        # KD-tree over last positions of active tracks\n",
    "        act_pos = np.array([active[p][\"position\"] for p in act_ids])\n",
    "        tree = cKDTree(act_pos)\n",
    "\n",
    "        # Query up to 2 nearest active tracks per detection within 'max_dist'\n",
    "        dists, a_idxs = tree.query(pos, k=2, distance_upper_bound=max_dist)\n",
    "\n",
    "        # Build candidate list with composite costs\n",
    "        poss_list = []\n",
    "        for i in range(len(pos)):\n",
    "            for k in range(2):\n",
    "                # Skip if outside radius or invalid index\n",
    "                if a_idxs[i, k] >= len(act_ids) or dists[i, k] == np.inf:\n",
    "                    continue\n",
    "                aid = act_ids[a_idxs[i, k]]\n",
    "                part = active[aid]\n",
    "\n",
    "                # Turning angle using previous point (if available)\n",
    "                prev_pt = part[\"history\"][-2] if len(part[\"history\"]) >= 2 else None\n",
    "                angle = calc_angle(prev_pt, part[\"position\"], pos[i])\n",
    "\n",
    "                # Appearance gate: reject if luminosity differs too much\n",
    "                lum_diff = abs(lum_arr[i] - part[\"luminosity\"])\n",
    "                if lum_diff > max_lum_diff:\n",
    "                    frame_skip_count += 1\n",
    "                    continue\n",
    "\n",
    "                # Composite cost terms\n",
    "                distance_cost = w_distance * dists[i, k]\n",
    "                angle_cost = w_angle * abs(angle)\n",
    "                lum_cost = w_lum * lum_diff\n",
    "                total_cost = distance_cost + angle_cost + lum_cost\n",
    "\n",
    "                # Accumulate diagnostics\n",
    "                frame_distance_cost += distance_cost\n",
    "                frame_angle_cost += angle_cost\n",
    "                frame_lum_cost += lum_cost\n",
    "                frame_candidate_count += 1\n",
    "\n",
    "                # Store candidate: (track_id, det_idx_in_pos, det_row_index, angle, dist, rank(1|2), total_cost)\n",
    "                poss_list.append((aid, i, idxs[i], angle, dists[i, k], k+1, total_cost))\n",
    "\n",
    "        # Update global diagnostics\n",
    "        overall_candidate_count += frame_candidate_count\n",
    "        overall_distance_cost += frame_distance_cost\n",
    "        overall_angle_cost += frame_angle_cost\n",
    "        overall_lum_cost += frame_lum_cost\n",
    "        overall_skip_count += frame_skip_count\n",
    "\n",
    "        # Greedy assignment by ascending total_cost\n",
    "        poss_list.sort(key=lambda x: x[6])\n",
    "        used_a = set()  # tracks already matched this frame\n",
    "        used_d = set()  # detections already matched this frame\n",
    "        fm = []         # accepted matches (aid, det_idx_in_pos, rank)\n",
    "\n",
    "        for candidate in poss_list:\n",
    "            aid, i, dii, angle, dist_val, rank, cost = candidate\n",
    "            if aid in used_a or i in used_d:\n",
    "                continue\n",
    "\n",
    "            part = active.get(aid)\n",
    "            if part is None:\n",
    "                continue\n",
    "\n",
    "            # Recompute angle/speed using the most recent point(s)\n",
    "            prev_pt = part[\"history\"][-2] if len(part[\"history\"]) >= 2 else None\n",
    "            angle = calc_angle(prev_pt, part[\"position\"], pos[i])\n",
    "            disp = pos[i] - part[\"position\"]\n",
    "            spd = np.linalg.norm(disp)\n",
    "            spd_ch = spd - part[\"previous_speed\"]\n",
    "\n",
    "            # Determine current/previous speed regimes\n",
    "            cm = \"low\" if spd <= params[\"slow_max_speed\"] else (\"medium\" if spd <= params[\"medium_max_speed\"] else \"high\")\n",
    "            pm = part[\"speed_mode\"]\n",
    "\n",
    "            # Build cumulative constraints along regime transition path\n",
    "            modes = [\"low\", \"medium\", \"high\"]\n",
    "            pi, ci = modes.index(pm), modes.index(cm)\n",
    "            seq = modes[pi:ci+1] if pi <= ci else modes[ci:pi+1]\n",
    "\n",
    "            cs_lim = {\"lower\": -np.inf, \"upper\": np.inf}  # speed-change limits\n",
    "            cd_lim = {\"lower\": -np.inf, \"upper\": np.inf}  # direction-change limits\n",
    "            for m in seq:\n",
    "                sp_lim = params[f\"{m}_speed_change_limits\"]\n",
    "                d_lim = params[f\"{m}_direction_change_limits\"]\n",
    "                cs_lim[\"lower\"] = max(cs_lim[\"lower\"], sp_lim[\"lower\"])\n",
    "                cs_lim[\"upper\"] = min(cs_lim[\"upper\"], sp_lim[\"upper\"])\n",
    "                cd_lim[\"lower\"] = max(cd_lim[\"lower\"], d_lim[\"lower\"])\n",
    "                cd_lim[\"upper\"] = min(cd_lim[\"upper\"], d_lim[\"upper\"])\n",
    "\n",
    "            # Enforce constraints; record rejects for diagnostics\n",
    "            rej = False\n",
    "            if not (cd_lim[\"lower\"] <= angle <= cd_lim[\"upper\"]):\n",
    "                stats.update_dir(cm, angle, params)\n",
    "                rej = True\n",
    "            if not (cs_lim[\"lower\"] <= spd_ch <= cs_lim[\"upper\"]):\n",
    "                stats.update_speed(cm, spd_ch, params)\n",
    "                rej = True\n",
    "            if rej:\n",
    "                part[\"frames_lost\"] += 1\n",
    "                if part[\"frames_lost\"] > params[\"memory\"]:\n",
    "                    # Drop track if memory exceeded\n",
    "                    del active[aid]\n",
    "                    del mm.length[aid]\n",
    "                continue\n",
    "\n",
    "            # Accept match\n",
    "            dets.at[dii, \"particle\"] = aid\n",
    "            fm.append((aid, i, rank))\n",
    "            used_a.add(aid)\n",
    "            used_d.add(i)\n",
    "            l1 += (rank == 1)\n",
    "            l2 += (rank == 2)\n",
    "\n",
    "        # Commit updates for accepted matches and update per-track regimes\n",
    "        new_pos = {}\n",
    "        new_lum = {}\n",
    "        mids = []\n",
    "        for aid, i, _ in fm:\n",
    "            new_pos[aid] = pos[i]\n",
    "            new_lum[aid] = lum_arr[i]\n",
    "            spd = np.linalg.norm(pos[i] - active[aid][\"position\"])\n",
    "            sm_val = \"low\" if spd <= params[\"slow_max_speed\"] else (\"medium\" if spd <= params[\"medium_max_speed\"] else \"high\")\n",
    "            active[aid][\"speed_mode\"] = sm_val\n",
    "            active[aid][\"previous_speed\"] = spd\n",
    "            stats.add_distance(sm_val, spd)\n",
    "            mids.append(aid)\n",
    "        mm.update(mids, new_pos, new_lum)\n",
    "\n",
    "        # Any unused detections spawn new tracks\n",
    "        un = set(range(len(fd))) - used_d\n",
    "        if un:\n",
    "            new_ids = list(range(pid, pid + len(un)))\n",
    "            pos_un = [pos[i] for i in un]\n",
    "            lum_un = [lum_arr[i] for i in un]\n",
    "            mm.add(new_ids, pos_un, lum_un)\n",
    "            for p, i in zip(new_ids, un):\n",
    "                dets.at[idxs[i], \"particle\"] = p\n",
    "            pid += len(un)\n",
    "\n",
    "    # Summary diagnostics for this tracker subset\n",
    "    num_tracks = dets[\"particle\"].nunique()\n",
    "    num_links = len(dets) - num_tracks\n",
    "    print(\"{}: Processed {} candidates; Total distance cost: {:.3f}, Total angle cost: {:.3f}, Total lum cost: {:.3f}; Total skipped (max_lum_diff): {}; Number of tracks: {}; Number of links: {}\".format(\n",
    "        tracker_name, overall_candidate_count, overall_distance_cost, overall_angle_cost, overall_lum_cost,\n",
    "        overall_skip_count, num_tracks, num_links))\n",
    "\n",
    "    # Nullable integer dtype for track ids\n",
    "    dets[\"particle\"] = dets[\"particle\"].astype(\"Int64\")\n",
    "\n",
    "    # Preserve direction’s natural ordering of frames in the output\n",
    "    return (dets.sort_values(\"frame\").reset_index(drop=True) if not asc else dets, l1, l2)\n",
    "\n",
    "\n",
    "def process_tracker_type(args):\n",
    "    \"\"\"\n",
    "    Run both forward and reverse linking for one detection subtype (e.g. 'small' or 'big').\n",
    "    Adds direction/type tags and builds a unique_id per produced track.\n",
    "    \"\"\"\n",
    "    t, sub, fwd_params, rev_params = args\n",
    "    stats_f = Statistics()\n",
    "    stats_r = Statistics()\n",
    "\n",
    "    # Forward pass\n",
    "    lf, _, _ = custom_link(sub.copy(), fwd_params, stats_f, asc=True, tracker_name=t + \"_forward\")\n",
    "    lf[\"link_direction\"] = \"forward\"\n",
    "    lf[\"tracker_type\"] = t + \"_forward\"\n",
    "    lf[\"unique_id\"] = lf[\"particle\"].apply(lambda x: f\"{t}_forward_{int(x)}\")\n",
    "\n",
    "    # Reverse pass\n",
    "    lr, _, _ = custom_link(sub.copy(), rev_params, stats_r, asc=False, tracker_name=t + \"_reverse\")\n",
    "    lr[\"link_direction\"] = \"reverse\"\n",
    "    lr[\"tracker_type\"] = t + \"_reverse\"\n",
    "    lr[\"unique_id\"] = lr[\"particle\"].apply(lambda x: f\"{t}_reverse_{int(x)}\")\n",
    "\n",
    "    return lf, lr\n",
    "\n",
    "\n",
    "def find_overlaps(df, dt, mcf):\n",
    "    \"\"\"\n",
    "    Find overlapping track pairs that are within 'dt' pixels for at least 'mcf'\n",
    "    consecutive frames. Returns:\n",
    "      - osm: dict[(idA,idB)] -> list of (start_frame, end_frame) segments\n",
    "      - tl: dict unique_id -> track length (# rows)\n",
    "    \"\"\"\n",
    "    # Group by frame to perform per-frame proximity queries\n",
    "    frame_groups = {f: group for f, group in df.groupby(\"frame\")}\n",
    "    tl = df.groupby(\"unique_id\").size().to_dict()  # track lengths\n",
    "\n",
    "    # For each frame, record pairs closer than dt\n",
    "    od = defaultdict(list)\n",
    "    for f, group in frame_groups.items():\n",
    "        pos = group[[\"x\", \"y\"]].values\n",
    "        parts = group[\"unique_id\"].values\n",
    "        if len(pos) == 0:\n",
    "            continue\n",
    "        tree = cKDTree(pos)\n",
    "        for i, j in tree.query_pairs(dt):\n",
    "            od[tuple(sorted((parts[i], parts[j])))].append(f)\n",
    "\n",
    "    # Convert per-frame hits into contiguous segments of length >= mcf\n",
    "    osm = {}\n",
    "    for c, fs in od.items():\n",
    "        fs = sorted(fs)\n",
    "        seg = []\n",
    "        s = fs[0]\n",
    "        p = fs[0]\n",
    "        for f in fs[1:]:\n",
    "            if f == p + 1:\n",
    "                p = f\n",
    "            else:\n",
    "                if p - s + 1 >= mcf:\n",
    "                    seg.append((s, p))\n",
    "                s = f\n",
    "                p = f\n",
    "        if p - s + 1 >= mcf:\n",
    "            seg.append((s, p))\n",
    "        if seg:\n",
    "            osm[c] = seg\n",
    "    return osm, tl\n",
    "\n",
    "\n",
    "def filter_tracks(df, osm, tl):\n",
    "    \"\"\"\n",
    "    For each overlapping pair, keep the longer track and remove the shorter\n",
    "    within the overlapping frame ranges only.\n",
    "    \"\"\"\n",
    "    rem = set()\n",
    "    for cl, segs in osm.items():\n",
    "        cll = {p: tl[p] for p in cl}\n",
    "        lp = max(cll, key=cll.get)       # track to keep\n",
    "        sp = [p for p in cl if p != lp]  # tracks to prune in overlap\n",
    "        for s, e in segs:\n",
    "            for p in sp:\n",
    "                indices = df[(df[\"unique_id\"] == p) & (df[\"frame\"] >= s) & (df[\"frame\"] <= e)].index.tolist()\n",
    "                rem.update(indices)\n",
    "    return df.drop(rem).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Pipeline:\n",
    "      1) Load detections (+ raw luminosity).\n",
    "      2) Split by original tracker_type (e.g. 'small'/'big').\n",
    "      3) Run forward and reverse linking; combine results.\n",
    "      4) Save combined tracks CSV (v2).\n",
    "      5) Detect overlaps and prune shorter duplicates.\n",
    "      6) Drop short tracks (< min_links) and save filtered CSV.\n",
    "    \"\"\"\n",
    "    _, _, _, fwd_params, rev_params, end_frame, min_links = get_config()\n",
    "\n",
    "    # List of detection CSVs to process (single file here)\n",
    "    det_files = [\"/Users/Ricardo/Desktop/Y4 Lab code/Work 0.3K/particle_detections.csv\"]\n",
    "\n",
    "    for det_file in det_files:\n",
    "        # Load detections with luminosity for the appearance term\n",
    "        det = pd.read_csv(det_file, usecols=[\"frame\", \"x\", \"y\", \"tracker_type\", \"raw_luminosity\"])\n",
    "\n",
    "        # Track each subtype independently (e.g., 'small' and 'big')\n",
    "        unique_types = det[\"tracker_type\"].unique()\n",
    "        res = []\n",
    "        for t in unique_types:\n",
    "            sub = det[det[\"tracker_type\"] == t].copy()\n",
    "            lf, lr = process_tracker_type((t, sub, fwd_params, rev_params))\n",
    "            res.extend([lf, lr])\n",
    "\n",
    "        # Combine forward+reverse outputs\n",
    "        comb = pd.concat(res, ignore_index=True)\n",
    "        total_tracks = comb[\"unique_id\"].nunique()\n",
    "        total_links = len(comb) - total_tracks\n",
    "        print(\"Combined Tracker: Total tracks: {}; Total links: {}\".format(total_tracks, total_links))\n",
    "\n",
    "        # Move 'raw_luminosity' to the end of the column order (purely cosmetic)\n",
    "        cols = [col for col in comb.columns if col != \"raw_luminosity\"] + [\"raw_luminosity\"]\n",
    "        comb = comb[cols]\n",
    "\n",
    "        # Save combined tracks\n",
    "        out_track = os.path.join(os.path.dirname(det_file), \"particle_tracks_v2.csv\")\n",
    "        comb.to_csv(out_track, index=False)\n",
    "\n",
    "        # Overlap detection parameters\n",
    "        dt = 3   # spatial radius to consider overlap (pixels)\n",
    "        mcf = 2  # minimum consecutive frames to qualify as an overlapping segment\n",
    "\n",
    "        # Compute overlaps and filter shorter track segments in conflict\n",
    "        osm, tl = find_overlaps(comb, dt, mcf)\n",
    "        filt = filter_tracks(comb, osm, tl)\n",
    "\n",
    "        # Keep only tracks with at least 'min_links' detections after pruning\n",
    "        cnt = filt[\"unique_id\"].value_counts()\n",
    "        filt = filt[filt[\"unique_id\"].isin(cnt[cnt >= min_links].index)].reset_index(drop=True)\n",
    "\n",
    "        # Report filtered stats\n",
    "        filt_tracks = filt[\"unique_id\"].nunique()\n",
    "        filt_links = len(filt) - filt_tracks\n",
    "        print(\"Filtered Tracker: Total tracks: {}; Total links: {}\".format(filt_tracks, filt_links))\n",
    "\n",
    "        # Reorder columns again for consistency and save\n",
    "        cols = [col for col in filt.columns if col != \"raw_luminosity\"] + [\"raw_luminosity\"]\n",
    "        filt = filt[cols]\n",
    "        out_filt = os.path.join(os.path.dirname(det_file), \"filtered_particle_tracks_v2.csv\")\n",
    "        filt.to_csv(out_filt, index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_forward: Processed 14889 candidates; Total distance cost: 231078.434, Total angle cost: 13452.558, Total lum cost: 22525.845; Total skipped: 1134; Number of tracks: 2319; Number of links: 5969\n",
      "small_reverse: Processed 14809 candidates; Total distance cost: 228085.767, Total angle cost: 12648.689, Total lum cost: 22447.516; Total skipped: 1141; Number of tracks: 2583; Number of links: 5705\n",
      "big_forward: Processed 13773 candidates; Total distance cost: 219520.097, Total angle cost: 12261.695, Total lum cost: 21042.776; Total skipped: 929; Number of tracks: 2088; Number of links: 5529\n",
      "big_reverse: Processed 13697 candidates; Total distance cost: 218273.187, Total angle cost: 11548.801, Total lum cost: 21001.235; Total skipped: 938; Number of tracks: 2330; Number of links: 5287\n",
      "Selected Tracker: small_forward: Total tracks: 110; Total links: 2497\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from scipy.spatial import cKDTree\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_config():\n",
    "    \"\"\"\n",
    "    Define tracking hyperparameters (forward and reverse) and global settings.\n",
    "    \"\"\"\n",
    "    base = \"/Users/Ricardo/Desktop/Y4 Lab code/Work 0.3K\"\n",
    "\n",
    "    # Forward-pass parameters (ascending frame order)\n",
    "    fwd_params = {\n",
    "        \"memory\": 0,  # tolerated consecutive missed frames before dropping a track\n",
    "\n",
    "        # Speed regime thresholds (pixels/frame)\n",
    "        \"slow_max_speed\": 6,\n",
    "        \"medium_max_speed\": 12,\n",
    "        \"high_max_speed\": 65,\n",
    "\n",
    "        # Allowed direction change (radians) per regime\n",
    "        \"low_direction_change_limits\": {\"lower\": -np.pi, \"upper\": np.pi},\n",
    "        \"medium_direction_change_limits\": {\"lower\": -0.4*np.pi, \"upper\": 0.4*np.pi},\n",
    "        \"high_direction_change_limits\": {\"lower\": -0.15*np.pi, \"upper\": 0.15*np.pi},\n",
    "\n",
    "        # Allowed speed change (Δ pixels/frame) per regime\n",
    "        \"low_speed_change_limits\": {\"lower\": -30, \"upper\": 50},\n",
    "        \"medium_speed_change_limits\": {\"lower\": -40, \"upper\": 55},\n",
    "        \"high_speed_change_limits\": {\"lower\": -50, \"upper\": 60},\n",
    "\n",
    "        # Multi-objective matching weights and luminosity gate\n",
    "        \"w_distance\": 1.0,  # weight for spatial distance\n",
    "        \"w_angle\": 1.0,     # weight for turning angle\n",
    "        \"w_lum\": 0.1,       # weight for luminosity difference\n",
    "        \"max_lum_diff\": 100 # hard cutoff for appearance mismatch\n",
    "    }\n",
    "\n",
    "    # Reverse-pass parameters (descending frame order)\n",
    "    rev_params = {\n",
    "        \"memory\": 0,\n",
    "        \"slow_max_speed\": 6,\n",
    "        \"medium_max_speed\": 12,\n",
    "        \"high_max_speed\": 65,\n",
    "        \"low_direction_change_limits\": {\"lower\": -np.pi, \"upper\": np.pi},\n",
    "        \"medium_direction_change_limits\": {\"lower\": -0.4*np.pi, \"upper\": 0.4*np.pi},\n",
    "        \"high_direction_change_limits\": {\"lower\": -0.15*np.pi, \"upper\": 0.15*np.pi},\n",
    "        \"low_speed_change_limits\": {\"lower\": -50, \"upper\": 30},\n",
    "        \"medium_speed_change_limits\": {\"lower\": -55, \"upper\": 40},\n",
    "        \"high_speed_change_limits\": {\"lower\": -60, \"upper\": 50},\n",
    "        \"w_distance\": 1.0,\n",
    "        \"w_angle\": 1.0,\n",
    "        \"w_lum\": 0.1,\n",
    "        \"max_lum_diff\": 100\n",
    "    }\n",
    "\n",
    "    end_frame = 600  # not directly used below; kept for consistency with your pipeline\n",
    "    min_links = 10   # minimum detections per track to retain\n",
    "    return (None, None, None, fwd_params, rev_params, end_frame, min_links)\n",
    "\n",
    "\n",
    "class MemoryManager:\n",
    "    \"\"\"\n",
    "    Holds active track states and simple lifecycle counters.\n",
    "    \"\"\"\n",
    "    def __init__(self, memory):\n",
    "        self.memory = memory          # tolerated consecutive misses\n",
    "        self.active = {}              # track_id -> state dict\n",
    "        self.length = {}              # track_id -> number of assigned detections\n",
    "\n",
    "    def add(self, ids, positions, luminosities):\n",
    "        \"\"\"\n",
    "        Start new tracks with initial (x,y) positions and luminosities.\n",
    "        \"\"\"\n",
    "        for i, p in enumerate(ids):\n",
    "            self.active[p] = {\n",
    "                \"position\": positions[i],          # last known position\n",
    "                \"history\": [positions[i]],         # trajectory history\n",
    "                \"luminosity\": luminosities[i],     # last luminosity\n",
    "                \"lum_history\": [luminosities[i]],  # luminosity history\n",
    "                \"frames_lost\": 0,                  # consecutive frames unmatched\n",
    "                \"previous_speed\": 0,               # last speed (pixels/frame)\n",
    "                \"speed_mode\": \"low\"                # 'low'|'medium'|'high'\n",
    "            }\n",
    "            self.length[p] = 1\n",
    "\n",
    "    def update(self, ids, new_positions, new_luminosities):\n",
    "        \"\"\"\n",
    "        Update matched tracks with new positions and luminosities.\n",
    "        \"\"\"\n",
    "        for p in ids:\n",
    "            if p in self.active:\n",
    "                self.active[p][\"history\"].append(new_positions[p])\n",
    "                self.active[p][\"position\"] = new_positions[p]\n",
    "                self.active[p][\"lum_history\"].append(new_luminosities[p])\n",
    "                self.active[p][\"luminosity\"] = new_luminosities[p]\n",
    "                self.length[p] += 1\n",
    "\n",
    "\n",
    "class Statistics:\n",
    "    \"\"\"\n",
    "    Collects diagnostics for rejected candidates and cumulative distances per regime.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.dir_stats = {\"low\": [], \"medium\": [], \"high\": []}     # rejected angle values\n",
    "        self.speed_stats = {\"low\": [], \"medium\": [], \"high\": []}   # rejected speed-change values\n",
    "        self.distances = {\"low\": 0, \"medium\": 0, \"high\": 0}        # accepted distances\n",
    "\n",
    "    def update_dir(self, mode, angle, params):\n",
    "        self.dir_stats[mode].append(angle)\n",
    "\n",
    "    def update_speed(self, mode, speed_change, params):\n",
    "        self.speed_stats[mode].append(speed_change)\n",
    "\n",
    "    def add_distance(self, mode, distance):\n",
    "        self.distances[mode] += distance\n",
    "\n",
    "\n",
    "def calc_angle_jit(prev, cur, nw):\n",
    "    \"\"\"\n",
    "    Signed turning angle between (prev->cur) and (cur->nw) in radians.\n",
    "    Returns 0 for degenerate segments.\n",
    "    \"\"\"\n",
    "    m1 = cur - prev\n",
    "    m2 = nw - cur\n",
    "    n1 = np.sqrt(m1[0]**2 + m1[1]**2)\n",
    "    n2 = np.sqrt(m2[0]**2 + m2[1]**2)\n",
    "    if n1 == 0 or n2 == 0:\n",
    "        return 0.0\n",
    "    dp = (m1[0]*m2[0] + m1[1]*m2[1]) / (n1*n2)\n",
    "    dp = min(max(dp, -1.0), 1.0)  # numerical safety\n",
    "    ang = np.arccos(dp)\n",
    "    # Use cross-product sign to assign orientation\n",
    "    if m1[0]*m2[1] - m1[1]*m2[0] < 0:\n",
    "        ang = -ang\n",
    "    return ang\n",
    "\n",
    "\n",
    "def calc_angle(prev, cur, nw):\n",
    "    \"\"\"\n",
    "    Safe wrapper: handle None and ensure float inputs.\n",
    "    \"\"\"\n",
    "    if prev is None:\n",
    "        return 0.0\n",
    "    return calc_angle_jit(np.asarray(prev, dtype=np.float64),\n",
    "                          np.asarray(cur,  dtype=np.float64),\n",
    "                          np.asarray(nw,   dtype=np.float64))\n",
    "\n",
    "\n",
    "def custom_link(dets, params, stats, asc=True, tracker_name=\"\"):\n",
    "    \"\"\"\n",
    "    Greedy, per-frame linking with composite matching cost and physical constraints:\n",
    "      • Composite cost = w_distance*distance + w_angle*|angle| + w_lum*|Δlum|\n",
    "      • Candidate gate on |Δlum| <= max_lum_diff\n",
    "      • After provisional pairing, enforce regime-specific direction & speed-change limits\n",
    "    \"\"\"\n",
    "    mem = params[\"memory\"]\n",
    "    max_dist = params[\"high_max_speed\"]  # KD-tree search radius (pixels)\n",
    "\n",
    "    # Cost weights and luminosity gate\n",
    "    w_distance = params[\"w_distance\"]\n",
    "    w_angle = params[\"w_angle\"]\n",
    "    w_lum = params[\"w_lum\"]\n",
    "    max_lum_diff = params[\"max_lum_diff\"]\n",
    "\n",
    "    pid = 0  # next track id to allocate\n",
    "\n",
    "    # Sort by frame according to pass direction\n",
    "    dets = dets.sort_values(\"frame\", ascending=asc).reset_index(drop=True)\n",
    "    dets[\"particle\"] = np.nan\n",
    "\n",
    "    mm = MemoryManager(mem)\n",
    "\n",
    "    # Diagnostics\n",
    "    l1 = l2 = 0                   # number of accepted 1st/2nd-nearest links\n",
    "    overall_candidate_count = 0\n",
    "    overall_distance_cost = 0.0\n",
    "    overall_angle_cost = 0.0\n",
    "    overall_lum_cost = 0.0\n",
    "    overall_skip_count = 0        # candidates skipped by luminosity gate\n",
    "\n",
    "    # Iterate frames\n",
    "    for f, fd in dets.groupby(\"frame\"):\n",
    "        # Per-frame diagnostics\n",
    "        frame_distance_cost = 0.0\n",
    "        frame_angle_cost = 0.0\n",
    "        frame_lum_cost = 0.0\n",
    "        frame_candidate_count = 0\n",
    "        frame_skip_count = 0\n",
    "\n",
    "        # Current detections\n",
    "        pos = fd[[\"x\", \"y\"]].values\n",
    "        lum_arr = fd[\"raw_luminosity\"].values\n",
    "        idxs = fd.index.values\n",
    "\n",
    "        # No active tracks: spawn all as new\n",
    "        if not mm.active:\n",
    "            new_ids = list(range(pid, pid + len(fd)))\n",
    "            mm.add(new_ids, list(pos), list(lum_arr))\n",
    "            dets.loc[idxs, \"particle\"] = new_ids\n",
    "            pid += len(fd)\n",
    "            continue\n",
    "\n",
    "        # Prefer longer-lived active tracks first\n",
    "        act_ids = sorted(mm.active.keys(), key=lambda p: mm.length[p], reverse=True)\n",
    "        active = mm.active\n",
    "\n",
    "        # Edge case: still none\n",
    "        if not act_ids:\n",
    "            new_ids = list(range(pid, pid + len(fd)))\n",
    "            mm.add(new_ids, list(pos), list(lum_arr))\n",
    "            dets.loc[idxs, \"particle\"] = new_ids\n",
    "            pid += len(fd)\n",
    "            continue\n",
    "\n",
    "        # KD-tree over active last positions\n",
    "        act_pos = np.array([active[p][\"position\"] for p in act_ids])\n",
    "        tree = cKDTree(act_pos)\n",
    "\n",
    "        # For each detection, query up to two nearest active tracks\n",
    "        dists, a_idxs = tree.query(pos, k=2, distance_upper_bound=max_dist)\n",
    "\n",
    "        # Build candidate list with composite cost\n",
    "        poss_list = []\n",
    "        for i in range(len(pos)):\n",
    "            for k in range(2):\n",
    "                if a_idxs[i, k] >= len(act_ids) or dists[i, k] == np.inf:\n",
    "                    continue\n",
    "                aid = act_ids[a_idxs[i, k]]\n",
    "                part = active[aid]\n",
    "\n",
    "                # Angle using previous point (if available)\n",
    "                prev_pt = part[\"history\"][-2] if len(part[\"history\"]) >= 2 else None\n",
    "                angle = calc_angle(prev_pt, part[\"position\"], pos[i])\n",
    "\n",
    "                # Appearance gate\n",
    "                lum_diff = abs(lum_arr[i] - part[\"luminosity\"])\n",
    "                if lum_diff > max_lum_diff:\n",
    "                    frame_skip_count += 1\n",
    "                    continue\n",
    "\n",
    "                # Composite cost\n",
    "                distance_cost = w_distance * dists[i, k]\n",
    "                angle_cost = w_angle * abs(angle)\n",
    "                lum_cost = w_lum * lum_diff\n",
    "                total_cost = distance_cost + angle_cost + lum_cost\n",
    "\n",
    "                # Accumulate diagnostics\n",
    "                frame_distance_cost += distance_cost\n",
    "                frame_angle_cost += angle_cost\n",
    "                frame_lum_cost += lum_cost\n",
    "                frame_candidate_count += 1\n",
    "\n",
    "                # (track_id, det_idx_in_pos, det_row_idx, angle, dist, rank(1|2), total_cost)\n",
    "                poss_list.append((aid, i, idxs[i], angle, dists[i, k], k+1, total_cost))\n",
    "\n",
    "        # Update global diagnostics\n",
    "        overall_candidate_count += frame_candidate_count\n",
    "        overall_distance_cost += frame_distance_cost\n",
    "        overall_angle_cost += frame_angle_cost\n",
    "        overall_lum_cost += frame_lum_cost\n",
    "        overall_skip_count += frame_skip_count\n",
    "\n",
    "        # Greedy assignment by lowest total_cost\n",
    "        poss_list.sort(key=lambda x: x[6])\n",
    "        used_a = set()  # matched tracks this frame\n",
    "        used_d = set()  # matched detections this frame\n",
    "        fm = []         # accepted matches: (aid, i, rank)\n",
    "\n",
    "        for candidate in poss_list:\n",
    "            aid, i, dii, angle, dist_val, rank, cost = candidate\n",
    "            if aid in used_a or i in used_d:\n",
    "                continue\n",
    "\n",
    "            part = active.get(aid)\n",
    "            if part is None:\n",
    "                continue\n",
    "\n",
    "            # Recompute final checks using freshest state\n",
    "            prev_pt = part[\"history\"][-2] if len(part[\"history\"]) >= 2 else None\n",
    "            angle = calc_angle(prev_pt, part[\"position\"], pos[i])\n",
    "            disp = pos[i] - part[\"position\"]\n",
    "            spd = np.linalg.norm(disp)\n",
    "            spd_ch = spd - part[\"previous_speed\"]\n",
    "\n",
    "            # Determine old/new regimes to build cumulative limits\n",
    "            cm = \"low\" if spd <= params[\"slow_max_speed\"] else (\"medium\" if spd <= params[\"medium_max_speed\"] else \"high\")\n",
    "            pm = part[\"speed_mode\"]\n",
    "            modes = [\"low\", \"medium\", \"high\"]\n",
    "            pi, ci = modes.index(pm), modes.index(cm)\n",
    "            seq = modes[pi:ci+1] if pi <= ci else modes[ci:pi+1]\n",
    "\n",
    "            # Aggregate limits along the transition path\n",
    "            cs_lim = {\"lower\": -np.inf, \"upper\": np.inf}  # speed-change\n",
    "            cd_lim = {\"lower\": -np.inf, \"upper\": np.inf}  # direction-change\n",
    "            for m in seq:\n",
    "                sp_lim = params[f\"{m}_speed_change_limits\"]\n",
    "                d_lim = params[f\"{m}_direction_change_limits\"]\n",
    "                cs_lim[\"lower\"] = max(cs_lim[\"lower\"], sp_lim[\"lower\"])\n",
    "                cs_lim[\"upper\"] = min(cs_lim[\"upper\"], sp_lim[\"upper\"])\n",
    "                cd_lim[\"lower\"] = max(cd_lim[\"lower\"], d_lim[\"lower\"])\n",
    "                cd_lim[\"upper\"] = min(cd_lim[\"upper\"], d_lim[\"upper\"])\n",
    "\n",
    "            # Enforce constraints; record rejects and optionally retire stale tracks\n",
    "            rej = False\n",
    "            if not (cd_lim[\"lower\"] <= angle <= cd_lim[\"upper\"]):\n",
    "                stats.update_dir(cm, angle, params)\n",
    "                rej = True\n",
    "            if not (cs_lim[\"lower\"] <= spd_ch <= cs_lim[\"upper\"]):\n",
    "                stats.update_speed(cm, spd_ch, params)\n",
    "                rej = True\n",
    "            if rej:\n",
    "                part[\"frames_lost\"] += 1\n",
    "                if part[\"frames_lost\"] > params[\"memory\"]:\n",
    "                    del active[aid]\n",
    "                    del mm.length[aid]\n",
    "                continue\n",
    "\n",
    "            # Accept pairing\n",
    "            dets.at[dii, \"particle\"] = aid\n",
    "            fm.append((aid, i, rank))\n",
    "            used_a.add(aid)\n",
    "            used_d.add(i)\n",
    "            l1 += (rank == 1)\n",
    "            l2 += (rank == 2)\n",
    "\n",
    "        # Commit accepted updates and update per-track regime/speed\n",
    "        new_pos = {}\n",
    "        new_lum = {}\n",
    "        mids = []\n",
    "        for aid, i, _ in fm:\n",
    "            new_pos[aid] = pos[i]\n",
    "            new_lum[aid] = lum_arr[i]\n",
    "            spd = np.linalg.norm(pos[i] - active[aid][\"position\"])\n",
    "            sm_val = \"low\" if spd <= params[\"slow_max_speed\"] else (\"medium\" if spd <= params[\"medium_max_speed\"] else \"high\")\n",
    "            active[aid][\"speed_mode\"] = sm_val\n",
    "            active[aid][\"previous_speed\"] = spd\n",
    "            stats.add_distance(sm_val, spd)\n",
    "            mids.append(aid)\n",
    "        mm.update(mids, new_pos, new_lum)\n",
    "\n",
    "        # Unmatched detections: spawn new tracks\n",
    "        un = set(range(len(fd))) - used_d\n",
    "        if un:\n",
    "            new_ids = list(range(pid, pid + len(un)))\n",
    "            pos_un = [pos[i] for i in un]\n",
    "            lum_un = [lum_arr[i] for i in un]\n",
    "            mm.add(new_ids, pos_un, lum_un)\n",
    "            for p, i in zip(new_ids, un):\n",
    "                dets.at[idxs[i], \"particle\"] = p\n",
    "            pid += len(un)\n",
    "\n",
    "    # Summary diagnostics for this pass\n",
    "    num_tracks = dets[\"particle\"].nunique()\n",
    "    num_links = len(dets) - num_tracks\n",
    "    print(\"{}: Processed {} candidates; Total distance cost: {:.3f}, Total angle cost: {:.3f}, Total lum cost: {:.3f}; Total skipped: {}; Number of tracks: {}; Number of links: {}\".format(\n",
    "        tracker_name, overall_candidate_count, overall_distance_cost, overall_angle_cost, overall_lum_cost,\n",
    "        overall_skip_count, num_tracks, num_links))\n",
    "\n",
    "    # Nullable integer for track ids\n",
    "    dets[\"particle\"] = dets[\"particle\"].astype(\"Int64\")\n",
    "\n",
    "    # Return as-is (already ordered per 'asc' during build)\n",
    "    return dets, l1, l2\n",
    "\n",
    "\n",
    "def process_tracker_type(args):\n",
    "    \"\"\"\n",
    "    Run forward and reverse linking for a given detection subtype,\n",
    "    then tag outputs with direction and construct unique ids.\n",
    "    \"\"\"\n",
    "    t, sub, fwd_params, rev_params = args\n",
    "    stats_f = Statistics()\n",
    "    stats_r = Statistics()\n",
    "\n",
    "    # Forward pass\n",
    "    lf, l1_f, l2_f = custom_link(sub.copy(), fwd_params, stats_f, asc=True, tracker_name=t+\"_forward\")\n",
    "    lf[\"link_direction\"] = \"forward\"\n",
    "    lf[\"tracker_type\"] = t+\"_forward\"\n",
    "    lf[\"unique_id\"] = lf[\"particle\"].apply(lambda x: f\"{t}_forward_{int(x)}\")\n",
    "\n",
    "    # Reverse pass\n",
    "    lr, l1_r, l2_r = custom_link(sub.copy(), rev_params, stats_r, asc=False, tracker_name=t+\"_reverse\")\n",
    "    lr[\"link_direction\"] = \"reverse\"\n",
    "    lr[\"tracker_type\"] = t+\"_reverse\"\n",
    "    lr[\"unique_id\"] = lr[\"particle\"].apply(lambda x: f\"{t}_reverse_{int(x)}\")\n",
    "\n",
    "    return lf, lr\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Pipeline:\n",
    "      1) Load detections with luminosity.\n",
    "      2) For each original tracker_type (e.g., 'small'/'big'), run forward & reverse linking.\n",
    "      3) Collect all candidate track sets.\n",
    "      4) Select the single best set by maximum #links (len(rows) - #tracks).\n",
    "      5) Drop short tracks (< min_links) and export CSV.\n",
    "    \"\"\"\n",
    "    _, _, _, fwd_params, rev_params, end_frame, min_links = get_config()\n",
    "\n",
    "    det_files = [\"/Users/Ricardo/Desktop/Y4 Lab code/Work 0.3K/particle_detections.csv\"]\n",
    "    candidates = []  # store each (type, direction) tracking output\n",
    "\n",
    "    for det_file in det_files:\n",
    "        # Load detections required by the linker\n",
    "        det = pd.read_csv(det_file, usecols=[\"frame\", \"x\", \"y\", \"tracker_type\", \"raw_luminosity\"])\n",
    "\n",
    "        # Build candidates per subtype\n",
    "        unique_types = det[\"tracker_type\"].unique()\n",
    "        for t in unique_types:\n",
    "            sub = det[det[\"tracker_type\"] == t].copy()\n",
    "            lf, lr = process_tracker_type((t, sub, fwd_params, rev_params))\n",
    "            candidates.append(lf)\n",
    "            candidates.append(lr)\n",
    "\n",
    "    # Choose the best candidate set by #links (a proxy for continuity)\n",
    "    best_df = None\n",
    "    best_links = -1\n",
    "    best_tracker = \"\"\n",
    "    for df in candidates:\n",
    "        tracks = df[\"unique_id\"].nunique()\n",
    "        links = len(df) - tracks\n",
    "        if links > best_links:\n",
    "            best_links = links\n",
    "            best_df = df\n",
    "            best_tracker = df[\"tracker_type\"].iloc[0]\n",
    "\n",
    "    # Prune short tracks\n",
    "    cnt = best_df[\"unique_id\"].value_counts()\n",
    "    best_df = best_df[best_df[\"unique_id\"].isin(cnt[cnt >= min_links].index)].reset_index(drop=True)\n",
    "\n",
    "    # Final stats and export\n",
    "    total_tracks = best_df[\"unique_id\"].nunique()\n",
    "    total_links = len(best_df) - total_tracks\n",
    "    print(\"Selected Tracker: {}: Total tracks: {}; Total links: {}\".format(best_tracker, total_tracks, total_links))\n",
    "\n",
    "    out_track = os.path.join(os.path.dirname(det_files[0]), \"filtered_particle_tracks_v2.csv\")\n",
    "\n",
    "    # Optional: move 'raw_luminosity' to the end for readability\n",
    "    cols = [col for col in best_df.columns if col != \"raw_luminosity\"] + [\"raw_luminosity\"]\n",
    "    best_df = best_df[cols]\n",
    "\n",
    "    best_df.to_csv(out_track, index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracked Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detections read: 15905 Unique tracks v1: 130 Unique tracks v2: 110\n",
      "Number of links v1: 2529 Number of links v2: 2497\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_config():\n",
    "    \"\"\"\n",
    "    Defines input and output paths, video processing parameters, \n",
    "    and returns them as a tuple for use in the pipeline.\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    base = \"/Users/Ricardo/Desktop/Y4 Lab code/Work 0.3K\"\n",
    "    video_dir = \"/Users/Ricardo/Desktop/Y4 Lab code/Cooldown 10\"\n",
    "\n",
    "    # Try to locate the input video\n",
    "    heatmap_inp = os.path.join(video_dir, \"_video (0).mp4\")\n",
    "    if not os.path.exists(heatmap_inp):\n",
    "        hits = glob.glob(os.path.join(video_dir, \"**\", \"_video (0).mp4\"), recursive=True)\n",
    "        if hits:\n",
    "            heatmap_inp = hits[0]\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Couldn't find '_video (0).mp4' under {video_dir}\")\n",
    "\n",
    "    # Define outputs for different processing steps\n",
    "    out0 = os.path.join(base, \"Original_Heatmap_NoDetections.mp4\")\n",
    "    out1 = os.path.join(base, \"Original_Heatmap.mp4\")\n",
    "    out2 = os.path.join(base, \"Background_Removed_Grayscale.mp4\")\n",
    "    out3 = os.path.join(base, \"Background_Removed_Heatmap.mp4\")\n",
    "    out4 = os.path.join(base, \"Temporal_Gaussian_Blur_Heatmap.mp4\")\n",
    "\n",
    "    # Region of interest (ROI) vertical limits\n",
    "    yl = 100\n",
    "    yu = 819\n",
    "    end_frame = 600\n",
    "\n",
    "    # Heatmap colour map\n",
    "    cmap = cv2.COLORMAP_JET\n",
    "\n",
    "    # Paths for track/detection data\n",
    "    filt_v1 = os.path.join(base, \"filtered_particle_tracks_v1.csv\")\n",
    "    filt_v2 = os.path.join(base, \"filtered_particle_tracks_v2.csv\")\n",
    "    det = os.path.join(base, \"particle_detections.csv\")\n",
    "    output_video = os.path.join(base, \"Show All Tracks.mp4\")\n",
    "\n",
    "    # Forwarding parameters: thresholds for motion speeds\n",
    "    fwd_params = {\"slow_max_speed\": 6, \"medium_max_speed\": 12, \"high_max_speed\": 65}\n",
    "\n",
    "    # Video drawing parameters\n",
    "    vid_params = {\"line_thickness\": 2, \"distance_threshold\": 3, \"min_consecutive_frames\": 2}\n",
    "\n",
    "    # Colour palettes for track visualisation\n",
    "    color_palettes = {\n",
    "        'small': (0, 255, 255),\n",
    "        'big': (0, 255, 0),\n",
    "        'small_reverse': (0, 0, 255),\n",
    "        'big_reverse': (0, 165, 255)\n",
    "    }\n",
    "\n",
    "    # Detection marker parameters\n",
    "    detection_params = {\"marker\": \"ring\", \"size\": 5}\n",
    "\n",
    "    # General processing parameters\n",
    "    proc_params = {\n",
    "        \"speed_factor\": 1,          # Playback speed (1 = real-time)\n",
    "        \"target_height\": 1080,      # Final video height\n",
    "        \"y_min\": 0,                 # Crop top\n",
    "        \"y_max\": 900,               # Crop bottom\n",
    "        \"start_frame\": 11,          # Starting frame index\n",
    "        \"end_frame\": 600            # Ending frame index\n",
    "    }\n",
    "\n",
    "    return (heatmap_inp, out1, out2, out3, out4, yl, yu, end_frame, cmap,\n",
    "            filt_v1, filt_v2, det, output_video, fwd_params,\n",
    "            vid_params, color_palettes, detection_params, proc_params)\n",
    "\n",
    "\n",
    "def apply_heatmap(frame, gray_roi, yl, yu, gmax, cmap):\n",
    "    \"\"\"\n",
    "    Normalises grayscale ROI and applies a heatmap colour map.\n",
    "    Places the coloured ROI back into the frame.\n",
    "    \"\"\"\n",
    "    norm = (gray_roi / gmax * 255).astype(np.uint8) if gmax > 0 else np.zeros_like(gray_roi, dtype=np.uint8)\n",
    "    heat = cv2.applyColorMap(np.clip(norm, 0, 255), cmap)\n",
    "    out = frame.copy()\n",
    "    out[yl:yu, :] = heat\n",
    "    return out\n",
    "\n",
    "\n",
    "def find_global_max(inp, coeffs, yl, yu, end_frame):\n",
    "    \"\"\"\n",
    "    Finds global maximum grayscale intensity in ROI across frames.\n",
    "    Used for consistent heatmap normalisation.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(inp)\n",
    "    if not cap.isOpened():\n",
    "        return None, None\n",
    "    gm1 = 0\n",
    "    gm2 = 0\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "    for frm in range(end_frame + 1):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        roi = gray[yl:yu, :]\n",
    "        gm1 = max(gm1, roi.max())\n",
    "        gm2 = max(gm2, roi.max())\n",
    "    cap.release()\n",
    "    return gm1, gm2\n",
    "\n",
    "\n",
    "def temporal_gaussian_blur(frames, kernel_size, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Applies temporal Gaussian blur across a sequence of frames \n",
    "    (smoothing motion over time).\n",
    "    \"\"\"\n",
    "    radius = kernel_size // 2\n",
    "    kernel = np.exp(-0.5 * (np.arange(-radius, radius + 1) / sigma) ** 2)\n",
    "    kernel = kernel / kernel.sum()\n",
    "\n",
    "    blurred = []\n",
    "    n = len(frames)\n",
    "\n",
    "    for i in range(n):\n",
    "        acc = np.zeros_like(frames[i], dtype=np.float32)\n",
    "        for j in range(-radius, radius + 1):\n",
    "            idx = i + j\n",
    "            # Handle boundary cases\n",
    "            if idx < 0:\n",
    "                idx = 0\n",
    "            elif idx >= n:\n",
    "                idx = n - 1\n",
    "            acc += frames[idx].astype(np.float32) * kernel[j + radius]\n",
    "        blurred.append(np.clip(acc, 0, 255).astype(np.uint8))\n",
    "    return blurred\n",
    "\n",
    "\n",
    "def prepare_segments(tracks):\n",
    "    \"\"\"\n",
    "    Converts dataframe of tracks into dictionary of segments by unique ID and frame.\n",
    "    \"\"\"\n",
    "    segs = {}\n",
    "    for _, row in tracks.iterrows():\n",
    "        f = int(row[\"frame\"])\n",
    "        pid = row[\"unique_id\"]\n",
    "        pos = (int(round(row[\"x\"])), int(round(row[\"y\"])))\n",
    "        tracker = row[\"tracker_type\"] if \"tracker_type\" in row else None\n",
    "        segs.setdefault(pid, {}).setdefault(f, []).append((pos, tracker))\n",
    "    return segs\n",
    "\n",
    "\n",
    "def draw_grey_tracks(frame, segs, history, fc, last_det, sm, mm_speed, th, color_palettes, dot_radius):\n",
    "    \"\"\"\n",
    "    Draws particle tracks (grey-scale for speed classification) on a frame.\n",
    "    Maintains history of tracks for continuity.\n",
    "    \"\"\"\n",
    "    def get_color(tracker, palettes):\n",
    "        if tracker is None:\n",
    "            return (255, 255, 255)\n",
    "        key = tracker.replace('_forward', '') if tracker.endswith('_forward') else tracker\n",
    "        return palettes.get(key, (255, 255, 255))\n",
    "\n",
    "    detected = set()\n",
    "\n",
    "    # Update current detections\n",
    "    for pid, frames in segs.items():\n",
    "        if fc in frames:\n",
    "            detected.add(pid)\n",
    "            # Reset history if track skipped a frame\n",
    "            if pid in last_det and fc != last_det[pid] + 1:\n",
    "                history[pid] = []\n",
    "            last_det[pid] = fc\n",
    "            history.setdefault(pid, []).extend(frames[fc])\n",
    "\n",
    "    # Draw tracks\n",
    "    for pid in list(history):\n",
    "        if pid in detected:\n",
    "            pts = history[pid]\n",
    "            for (pt1, _), (pt2, _) in zip(pts, pts[1:]):\n",
    "                d = np.linalg.norm(np.array(pt2) - np.array(pt1))\n",
    "                # Colour line based on distance (speed proxy)\n",
    "                line_color = (0, 0, 0) if d < sm else ((128, 128, 128) if d < mm_speed else (255, 255, 255))\n",
    "                cv2.line(frame, pt1, pt2, line_color, th)\n",
    "            for (pt, tracker) in pts:\n",
    "                dot_color = get_color(tracker, color_palettes)\n",
    "                cv2.circle(frame, pt, dot_radius, dot_color, thickness=-1)\n",
    "        else:\n",
    "            # Remove old tracks not detected anymore\n",
    "            history.pop(pid)\n",
    "            last_det.pop(pid, None)\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "def process_combined_video_only(heatmap_inp, df_tracks_v1, df_tracks_v2, df_det,\n",
    "                                fwd_params, vid_params, color_palettes, detection_params,\n",
    "                                proc_params, gm1, cmap, output_video, yl, yu):\n",
    "    \"\"\"\n",
    "    Main video processing pipeline:\n",
    "    - Reads video frames\n",
    "    - Applies heatmap and temporal blur\n",
    "    - Draws detections and tracks\n",
    "    - Combines multiple visualisations side-by-side\n",
    "    - Writes combined output video\n",
    "    \"\"\"\n",
    "    def get_color(tracker, palettes):\n",
    "        key = tracker.replace('_forward', '') if isinstance(tracker, str) and tracker.endswith('_forward') else tracker\n",
    "        return palettes.get(key, (255, 255, 255))\n",
    "\n",
    "    cap = cv2.VideoCapture(heatmap_inp)\n",
    "    if not cap.isOpened():\n",
    "        raise FileNotFoundError(f\"Could not open video: {heatmap_inp}\")\n",
    "\n",
    "    # Get video info\n",
    "    total_frames_in_video = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
    "\n",
    "    start_frame = max(0, int(proc_params[\"start_frame\"]))\n",
    "    end_frame_req = int(proc_params[\"end_frame\"])\n",
    "\n",
    "    # Adjust end frame if video shorter\n",
    "    if total_frames_in_video > 0:\n",
    "        end_frame = min(end_frame_req, total_frames_in_video - 1)\n",
    "    else:\n",
    "        end_frame = end_frame_req\n",
    "\n",
    "    if start_frame > end_frame:\n",
    "        raise ValueError(f\"start_frame ({start_frame}) is after end_frame ({end_frame}). \"\n",
    "                         f\"Video frame count: {total_frames_in_video}\")\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    heatmap_frames = []\n",
    "    roi_frames = []\n",
    "\n",
    "    # Read frames and apply heatmap\n",
    "    for fidx in range(start_frame, end_frame + 1):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        roi = gray[yl:yu, :]\n",
    "        hm = apply_heatmap(frame, roi, yl, yu, gm1, cmap)\n",
    "        heatmap_frames.append(hm)\n",
    "        roi_frames.append(hm[yl:yu, :])\n",
    "    cap.release()\n",
    "\n",
    "    if len(heatmap_frames) == 0:\n",
    "        raise RuntimeError(\n",
    "            f\"No frames were read. Check that the video path is correct, and that \"\n",
    "            f\"start_frame ({start_frame}) <= end_frame ({end_frame}). \"\n",
    "            f\"Detected total_frames_in_video={total_frames_in_video}.\"\n",
    "        )\n",
    "\n",
    "    # Temporal blur of ROI frames\n",
    "    kernel_size = 5 if len(roi_frames) >= 3 else max(1, len(roi_frames) | 1)\n",
    "    blurred_roi_frames = temporal_gaussian_blur(roi_frames, kernel_size, 1.0)\n",
    "\n",
    "    # Video output setup\n",
    "    h_frame, w_frame, _ = heatmap_frames[0].shape\n",
    "    target_height = int(proc_params[\"target_height\"])\n",
    "    y_min_final = int(proc_params[\"y_min\"])\n",
    "    y_max_final = int(proc_params[\"y_max\"])\n",
    "    crop_height = max(1, y_max_final - y_min_final)\n",
    "    scale = target_height / crop_height\n",
    "    resized_width = int(round(w_frame * scale))\n",
    "    total_width = 5 * resized_width\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"avc1\")\n",
    "    out = cv2.VideoWriter(output_video, fourcc, fps, (total_width, target_height))\n",
    "\n",
    "    # Prepare tracking data\n",
    "    segs_v1 = prepare_segments(df_tracks_v1)\n",
    "    segs_v2 = prepare_segments(df_tracks_v2)\n",
    "    det_frame_groups = {int(f): group for f, group in df_det.groupby(\"frame\")}\n",
    "    history_grey_v1, last_det_v1 = {}, {}\n",
    "    history_grey_v2, last_det_v2 = {}, {}\n",
    "\n",
    "    sm = fwd_params[\"slow_max_speed\"]\n",
    "    mm_speed = fwd_params[\"medium_max_speed\"]\n",
    "    th = vid_params[\"line_thickness\"]\n",
    "    speed_factor = proc_params[\"speed_factor\"]\n",
    "    dot_radius = 1\n",
    "\n",
    "    frame_num = start_frame\n",
    "    i = 0\n",
    "    total_frames = len(heatmap_frames)\n",
    "\n",
    "    # Main frame loop\n",
    "    while i < total_frames:\n",
    "        base_frame = heatmap_frames[i]\n",
    "\n",
    "        # Add temporal Gaussian blur\n",
    "        tgb_frame = base_frame.copy()\n",
    "        tgb_frame[yl:yu, :] = blurred_roi_frames[i]\n",
    "\n",
    "        # Add detections\n",
    "        frame_detect = base_frame.copy()\n",
    "        if frame_num in det_frame_groups:\n",
    "            cur_det = det_frame_groups[frame_num]\n",
    "            for _, row in cur_det.iterrows():\n",
    "                x = int(row[\"x\"]); y = int(row[\"y\"])\n",
    "                tracker = row.get(\"tracker_type\", None)\n",
    "                color = get_color(tracker, color_palettes)\n",
    "                mk = detection_params[\"marker\"]\n",
    "                sz = int(detection_params[\"size\"])\n",
    "                if mk == \"circle\":\n",
    "                    cv2.circle(frame_detect, (x, y), sz, color, -1)\n",
    "                elif mk == \"cross\":\n",
    "                    cv2.line(frame_detect, (x - sz, y - sz), (x + sz, y + sz), color, th)\n",
    "                    cv2.line(frame_detect, (x - sz, y + sz), (x + sz, y - sz), color, th)\n",
    "                else:  # default: ring\n",
    "                    cv2.circle(frame_detect, (x, y), sz, color, 1)\n",
    "\n",
    "        # Add grey tracks from v1 and v2\n",
    "        frame_grey_v1 = draw_grey_tracks(base_frame.copy(), segs_v1, history_grey_v1,\n",
    "                                         frame_num, last_det_v1, sm, mm_speed, th, color_palettes, dot_radius)\n",
    "        frame_grey_v2 = draw_grey_tracks(base_frame.copy(), segs_v2, history_grey_v2,\n",
    "                                         frame_num, last_det_v2, sm, mm_speed, th, color_palettes, dot_radius)\n",
    "\n",
    "        # Combine the five different views horizontally\n",
    "        ordered = [base_frame, tgb_frame, frame_detect, frame_grey_v1, frame_grey_v2]\n",
    "        crops = []\n",
    "        for fr in ordered:\n",
    "            crop = fr[y_min_final:y_max_final, :]\n",
    "            resized = cv2.resize(crop, (resized_width, target_height))\n",
    "            crops.append(resized)\n",
    "        combined_frame = cv2.hconcat(crops)\n",
    "\n",
    "        # Write output\n",
    "        out.write(combined_frame)\n",
    "\n",
    "        # Update frame counters (account for speed factor)\n",
    "        i += 1\n",
    "        frame_num += 1\n",
    "        if speed_factor > 1:  # skip frames\n",
    "            skip = int(round(speed_factor))\n",
    "            i += skip - 1\n",
    "            frame_num += skip - 1\n",
    "        elif speed_factor < 1:  # duplicate frames\n",
    "            rep = int(round(1 / speed_factor)) - 1\n",
    "            for _ in range(rep):\n",
    "                out.write(combined_frame)\n",
    "\n",
    "    out.release()\n",
    "    print(\"Combined video processing complete\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main entry point:\n",
    "    - Loads paths and parameters\n",
    "    - Finds global max for heatmap normalisation\n",
    "    - Loads track/detection CSVs\n",
    "    - Runs combined video processing\n",
    "    \"\"\"\n",
    "    (heatmap_inp, out1, out2, out3, out4, yl, yu, end_frame, cmap,\n",
    "     filt_v1, filt_v2, det, output_video, fwd_params,\n",
    "     vid_params, color_palettes, detection_params, proc_params) = get_config()\n",
    "\n",
    "    # Default coefficients (unused in this version)\n",
    "    default_coeff = {frm: [0, 0, 0, 0, 0, 0] for frm in range(end_frame + 1)}\n",
    "\n",
    "    # Find global max values for normalisation\n",
    "    gm1, gm2 = find_global_max(heatmap_inp, default_coeff, yl, yu, end_frame)\n",
    "\n",
    "    # Load CSVs with track and detection data\n",
    "    df_tracks_v1 = pd.read_csv(filt_v1)\n",
    "    df_tracks_v2 = pd.read_csv(filt_v2)\n",
    "    df_det = pd.read_csv(det)\n",
    "\n",
    "    print(\"Detections read:\", len(df_det),\n",
    "          \"Unique tracks v1:\", len(df_tracks_v1[\"unique_id\"].unique()),\n",
    "          \"Unique tracks v2:\", len(df_tracks_v2[\"unique_id\"].unique()))\n",
    "\n",
    "    # Count links (track continuity measure)\n",
    "    links_v1 = df_tracks_v1.groupby(\"unique_id\").size().apply(lambda n: n - 1 if n > 0 else 0).sum()\n",
    "    links_v2 = df_tracks_v2.groupby(\"unique_id\").size().apply(lambda n: n - 1 if n > 0 else 0).sum()\n",
    "    print(\"Number of links v1:\", links_v1, \"Number of links v2:\", links_v2)\n",
    "\n",
    "    # Process video\n",
    "    process_combined_video_only(heatmap_inp, df_tracks_v1, df_tracks_v2, df_det,\n",
    "                                fwd_params, vid_params, color_palettes, detection_params,\n",
    "                                proc_params, gm1, cmap, output_video, yl, yu)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import ipyevents\n",
    "from IPython.display import display, HTML\n",
    "import copy\n",
    "import asyncio\n",
    "import uuid\n",
    "\n",
    "def get_config():\n",
    "    \"\"\"\n",
    "    Centralised configuration: file paths, UI sizes, and processing parameters.\n",
    "    \"\"\"\n",
    "    base = \"/Users/Ricardo/Desktop/Y4 Lab code/Work 0.3K\"\n",
    "    heatmap_inp = os.path.join(\"/Users/Ricardo/Desktop/Y4 Lab code/Cooldown 10\", \"_video (0).mp4\")\n",
    "\n",
    "    # ROI vertical bounds and frame limit for scanning\n",
    "    yl, yu, end_frame = 100, 819, 600\n",
    "\n",
    "    # Colour map for heatmap overlay\n",
    "    cmap = cv2.COLORMAP_JET\n",
    "\n",
    "    # Tracks CSV (auto-replaced by updated_file if present)\n",
    "    tracks_csv_path = os.path.join(base, \"filtered_particle_tracks_v2.csv\")\n",
    "\n",
    "    # Frame range to load from the video\n",
    "    proc_params = {\"start_frame\": 11, \"end_frame\": 600}\n",
    "\n",
    "    # Widget display width for side-by-side panels\n",
    "    display_width = 200\n",
    "\n",
    "    # Line thickness for track segments\n",
    "    linke_thickness = 1\n",
    "\n",
    "    # Where interactive edits are saved\n",
    "    updated_file = os.path.join(base, \"filtered_particle_tracks_updated.csv\")\n",
    "\n",
    "    return (heatmap_inp, yl, yu, end_frame, cmap, tracks_csv_path,\n",
    "            proc_params, display_width, linke_thickness, updated_file)\n",
    "\n",
    "\n",
    "def temporal_gaussian_blur(frames, kernel_size, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Apply 1D Gaussian blur across the time axis to a list of ROI frames.\n",
    "    Edges are clamped to the nearest valid frame.\n",
    "    \"\"\"\n",
    "    radius = kernel_size // 2\n",
    "    kernel = np.exp(-0.5 * (np.arange(-radius, radius + 1) / sigma) ** 2)\n",
    "    kernel /= kernel.sum()\n",
    "\n",
    "    blurred = []\n",
    "    n = len(frames)\n",
    "    for i in range(n):\n",
    "        acc = np.zeros_like(frames[i], dtype=np.float32)\n",
    "        for j in range(-radius, radius + 1):\n",
    "            idx = i + j\n",
    "            idx = max(0, min(idx, n - 1))  # clamp at boundaries\n",
    "            acc += frames[idx].astype(np.float32) * kernel[j + radius]\n",
    "        blurred.append(np.clip(acc, 0, 255).astype(np.uint8))\n",
    "    return blurred\n",
    "\n",
    "\n",
    "def find_global_max(video_path, yl, yu, end_frame):\n",
    "    \"\"\"\n",
    "    Scan the first end_frame+1 frames of the input video to get the global\n",
    "    maximum intensity in the ROI (yl:yu). Used for heatmap normalisation.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    gm = 0\n",
    "    for _ in range(end_frame + 1):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        roi = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)[yl:yu, :]\n",
    "        gm = max(gm, int(roi.max()))\n",
    "    cap.release()\n",
    "    return gm\n",
    "\n",
    "\n",
    "def prepare_segments(tracks):\n",
    "    \"\"\"\n",
    "    Convert a tracks DataFrame into a nested dict:\n",
    "      {unique_id: {frame: [(x, y, BGR_color), ...], ...}, ...}\n",
    "    If a 'color' column exists, map string labels to BGR tuples; default is brown.\n",
    "    \"\"\"\n",
    "    segs = {}\n",
    "    has_color = \"color\" in tracks.columns\n",
    "\n",
    "    for _, r in tracks.iterrows():\n",
    "        pid = r[\"unique_id\"]\n",
    "        f = int(r[\"frame\"])\n",
    "        x = int(round(r[\"x\"]))\n",
    "        y = int(round(r[\"y\"]))\n",
    "\n",
    "        # Default BGR colour (brown-ish)\n",
    "        color_val = (29, 101, 181)\n",
    "\n",
    "        if has_color:\n",
    "            col = r[\"color\"]\n",
    "            if isinstance(col, str):\n",
    "                # Map string to BGR\n",
    "                if col.lower() == \"brown\":      # default mapping\n",
    "                    color_val = (29, 101, 181)\n",
    "                elif col.lower() == \"green\":\n",
    "                    color_val = (0, 255, 0)\n",
    "                elif col.lower() == \"yellow\":\n",
    "                    color_val = (0, 255, 255)\n",
    "                else:\n",
    "                    color_val = (29, 101, 181)\n",
    "\n",
    "        segs.setdefault(pid, {}).setdefault(f, []).append((x, y, color_val))\n",
    "    return segs\n",
    "\n",
    "\n",
    "def draw_tracks(frame, tracks, history, fc, last_det, linke_thickness):\n",
    "    \"\"\"\n",
    "    Draw ‘existing’ tracks on a frame using their accumulated history.\n",
    "    History is reset if there’s a gap between consecutive detections.\n",
    "    \"\"\"\n",
    "    dot_radius = 1\n",
    "    detected = set()\n",
    "\n",
    "    # Accumulate detections for this frame into history\n",
    "    for pid, frames_dict in tracks.items():\n",
    "        if fc in frames_dict:\n",
    "            detected.add(pid)\n",
    "            if pid in last_det and fc != last_det[pid] + 1:\n",
    "                history[pid] = []          # reset path if there was a gap\n",
    "            last_det[pid] = fc\n",
    "            history.setdefault(pid, []).extend(frames_dict[fc])\n",
    "\n",
    "    # Draw paths + points for any track that has data in history at this frame\n",
    "    for pid in list(history):\n",
    "        if pid in detected:\n",
    "            pts = history[pid]\n",
    "            # Lines between consecutive points\n",
    "            for pt1, pt2 in zip(pts, pts[1:]):\n",
    "                cv2.line(frame, pt1[:2], pt2[:2], (0, 0, 0), linke_thickness)\n",
    "            # Dots at each detection, coloured per-track\n",
    "            for pt in pts:\n",
    "                col = pt[2] if len(pt) >= 3 else (29, 101, 181)\n",
    "                cv2.circle(frame, pt[:2], dot_radius, col, thickness=-1)\n",
    "        else:\n",
    "            # Track not seen this frame; drop its history\n",
    "            history.pop(pid)\n",
    "            last_det.pop(pid)\n",
    "    return frame\n",
    "\n",
    "\n",
    "def draw_manual_track(track, frame_img, current_rel_frame, linke_thickness):\n",
    "    \"\"\"\n",
    "    Draw a user-built manual track up to the current relative frame.\n",
    "    Track items: (rel_frame, (x,y) or (x,y,?), color[, snapped_track_id])\n",
    "    \"\"\"\n",
    "    dot_radius = 1\n",
    "    pts = [pt for pt in track if pt[0] <= current_rel_frame]\n",
    "    if not pts:\n",
    "        return frame_img\n",
    "\n",
    "    # Lines only between different frames for visual continuity\n",
    "    for (f1, pos1, *_), (f2, pos2, *_) in zip(pts, pts[1:]):\n",
    "        cv2.line(frame_img, pos1[:2], pos2[:2], (0, 0, 0), linke_thickness)\n",
    "\n",
    "    # Points\n",
    "    for (f, pos, col, *_) in pts:\n",
    "        cv2.circle(frame_img, pos[:2] if len(pos) > 2 else pos, dot_radius, col, thickness=-1)\n",
    "    return frame_img\n",
    "\n",
    "\n",
    "def draw_merged_track(merged, frame_img, current_abs_frame, linke_thickness):\n",
    "    \"\"\"\n",
    "    Draw a merged track (list of (abs_frame, (x,y[,?]), color)) up to current absolute frame.\n",
    "    \"\"\"\n",
    "    dot_radius = 1\n",
    "    pts = [pt for pt in merged if pt[0] <= current_abs_frame]\n",
    "    if not pts:\n",
    "        return frame_img\n",
    "\n",
    "    for (f1, pos1, _), (f2, pos2, _) in zip(pts, pts[1:]):\n",
    "        cv2.line(frame_img, pos1[:2], pos2[:2], (0, 0, 0), linke_thickness)\n",
    "\n",
    "    for f, pos, col in pts:\n",
    "        cv2.circle(frame_img, pos[:2] if len(pos) > 2 else pos, dot_radius, col, thickness=-1)\n",
    "    return frame_img\n",
    "\n",
    "\n",
    "def interactive_video_widget(normal_frames, summed_frames, segs, start_frame,\n",
    "                             display_width, linke_thickness, yl, yu, updated_file):\n",
    "    \"\"\"\n",
    "    Build and display the interactive widget:\n",
    "      • Left pane: current frame (cropped & scaled)\n",
    "      • Centre pane: working panel with tracks/detections drawn\n",
    "      • Right pane: controls (toggles, slider, save/undo, simple trim editor)\n",
    "    Includes:\n",
    "      - Drawing manual tracks (optionally snap to detections)\n",
    "      - Merging manual segments into existing tracks\n",
    "      - Undo stack and keyboard shortcuts\n",
    "      - Save to CSV (updated_file)\n",
    "    \"\"\"\n",
    "    # Helper to assign unique ids to standalone manual tracks\n",
    "    def generate_manual_track_id():\n",
    "        return \"manual_\" + uuid.uuid4().hex[:8]\n",
    "\n",
    "    # Nested draw function specific to this widget context (includes frame tags)\n",
    "    def draw_tracks(frame, tracks, history, fc, last_det, linke_thickness):\n",
    "        dot_radius = 1\n",
    "        detected = set()\n",
    "        for pid, frames_dict in tracks.items():\n",
    "            if fc in frames_dict:\n",
    "                detected.add(pid)\n",
    "                if pid in last_det and fc != last_det[pid] + 1:\n",
    "                    history[pid] = []\n",
    "                last_det[pid] = fc\n",
    "                # Keep the frame index with the point for continuity checks\n",
    "                for (x, y, col) in frames_dict[fc]:\n",
    "                    history.setdefault(pid, []).append((x, y, col, fc))\n",
    "        for pid in list(history):\n",
    "            if pid in detected:\n",
    "                pts = history[pid]\n",
    "                for pt1, pt2 in zip(pts, pts[1:]):\n",
    "                    if pt1[3] != pt2[3]:\n",
    "                        cv2.line(frame, pt1[:2], pt2[:2], (0, 0, 0), linke_thickness)\n",
    "                for pt in pts:\n",
    "                    cv2.circle(frame, pt[:2], dot_radius, pt[2], thickness=-1)\n",
    "            else:\n",
    "                history.pop(pid)\n",
    "                last_det.pop(pid)\n",
    "        return frame\n",
    "\n",
    "    def draw_manual_track(track, frame_img, current_rel_frame, linke_thickness):\n",
    "        dot_radius = 1\n",
    "        pts = [pt for pt in track if pt[0] <= current_rel_frame]\n",
    "        if not pts:\n",
    "            return frame_img\n",
    "        for (f1, pos1, col1, snap1), (f2, pos2, col2, snap2) in zip(pts, pts[1:]):\n",
    "            if f1 != f2:\n",
    "                cv2.line(frame_img, pos1[:2], pos2[:2], (0, 0, 0), linke_thickness)\n",
    "        for (f, pos, col, snap) in pts:\n",
    "            cv2.circle(frame_img, pos[:2], dot_radius, col, thickness=-1)\n",
    "        return frame_img\n",
    "\n",
    "    def draw_merged_track(merged, frame_img, current_abs_frame, linke_thickness):\n",
    "        dot_radius = 1\n",
    "        pts = [pt for pt in merged if pt[0] <= current_abs_frame]\n",
    "        if not pts:\n",
    "            return frame_img\n",
    "        for (f1, pos1, col1), (f2, pos2, col2) in zip(pts, pts[1:]):\n",
    "            if f1 != f2:\n",
    "                cv2.line(frame_img, pos1[:2], pos2[:2], (0, 0, 0), linke_thickness)\n",
    "        for f, pos, col in pts:\n",
    "            cv2.circle(frame_img, pos[:2], dot_radius, col, thickness=-1)\n",
    "        return frame_img\n",
    "\n",
    "    # Try to load detections to enable “snap to nearest detection” behaviour\n",
    "    try:\n",
    "        df_detections = pd.read_csv(os.path.join(os.path.dirname(updated_file), \"particle_detections.csv\"))\n",
    "        detection_markers = {}\n",
    "        for _, r in df_detections.iterrows():\n",
    "            frm = int(r[\"frame\"])\n",
    "            pos = (int(round(r[\"x\"])), int(round(r[\"y\"])))\n",
    "            detection_markers.setdefault(frm, []).append(pos)\n",
    "    except Exception:\n",
    "        detection_markers = {}\n",
    "\n",
    "    # UI controls (with a neutral button colour theme)\n",
    "    button_color = \"#808080\"\n",
    "    video_mode_toggle = widgets.ToggleButton(value=False, description=\"Summed Video\", button_style='')\n",
    "    video_mode_toggle.style.button_color = button_color\n",
    "\n",
    "    snap_track_toggle = widgets.ToggleButton(value=True, description=\"Snap Track\", button_style='')\n",
    "    snap_track_toggle.style.button_color = button_color\n",
    "\n",
    "    allow_merge_toggle = widgets.ToggleButton(value=False, description=\"Allow Merge\", button_style='')\n",
    "    allow_merge_toggle.style.button_color = button_color\n",
    "\n",
    "    draw_toggle = widgets.ToggleButton(value=True, description=\"Draw Track\", button_style='')\n",
    "    draw_toggle.style.button_color = button_color\n",
    "\n",
    "    undo_button = widgets.Button(description=\"Undo\", button_style='')\n",
    "    undo_button.style.button_color = button_color\n",
    "\n",
    "    save_button = widgets.Button(description=\"Save Changes\", button_style='')\n",
    "    save_button.style.button_color = button_color\n",
    "\n",
    "    # Helper to select which video buffer is active (normal vs temporally blurred)\n",
    "    def get_current_frames():\n",
    "        return summed_frames if video_mode_toggle.value else normal_frames\n",
    "\n",
    "    # Render the frame at index i with tracks up to that frame\n",
    "    def compute_frame(i, tracks):\n",
    "        base = get_current_frames()\n",
    "        history = {}\n",
    "        last_det = {}\n",
    "        frame_number = start_frame\n",
    "        interactive_frame = None\n",
    "        for idx in range(i + 1):\n",
    "            frame = base[idx].copy()\n",
    "            frame = draw_tracks(frame, tracks, history, frame_number, last_det, linke_thickness)\n",
    "            interactive_frame = frame\n",
    "            frame_number += 1\n",
    "        return interactive_frame, history\n",
    "\n",
    "    # Small wrappers to pass configured thickness\n",
    "    def draw_manual_track_wrapper(track, frame_img, current_abs_frame):\n",
    "        return draw_manual_track(track, frame_img, current_abs_frame, linke_thickness)\n",
    "\n",
    "    def draw_merged_track_wrapper(merged, frame_img, current_abs_frame):\n",
    "        return draw_merged_track(merged, frame_img, current_abs_frame, linke_thickness)\n",
    "\n",
    "    # Left static image (without overlays) for reference\n",
    "    left_img_widget = widgets.Image(format=\"png\", layout=widgets.Layout(width=f\"{display_width}px\"))\n",
    "\n",
    "    def update_left_image(i):\n",
    "        frame = get_current_frames()[i]\n",
    "        cropped = frame[yl:yu, :]\n",
    "        h, w = cropped.shape[:2]\n",
    "        scale = display_width / w\n",
    "        resized = cv2.resize(cropped, (display_width, int(h * scale)))\n",
    "        _, buf = cv2.imencode(\".png\", resized)\n",
    "        left_img_widget.value = buf.tobytes()\n",
    "\n",
    "    # Main image with overlays (tracks / manual edits)\n",
    "    img_widget = widgets.Image(format=\"png\", layout=widgets.Layout(width=f\"{display_width}px\"))\n",
    "\n",
    "    # Frame slider (0-based index into loaded frames array)\n",
    "    slider = widgets.IntSlider(value=0, min=0, max=len(normal_frames) - 1, description=\"\", readout=True)\n",
    "\n",
    "    # Working copies / state\n",
    "    active_segs = copy.deepcopy(segs)  # can be modified interactively\n",
    "    merged_tracks = []                 # list of (snap_track_id, merged_points_list)\n",
    "    current_history = {}\n",
    "    selected_track = None\n",
    "\n",
    "    # Manual drawing state\n",
    "    manual_tracks = []                 # completed manual tracks\n",
    "    current_manual_track = None        # in-progress manual track\n",
    "    undo_stack = []                    # actions to allow undo\n",
    "\n",
    "    # Common colours (BGR)\n",
    "    brown = (29, 101, 181)\n",
    "    yellow = (0, 255, 255)\n",
    "    green = (0, 255, 0)\n",
    "\n",
    "    # Re-render the UI images for the current slider position\n",
    "    def update_image(i):\n",
    "        nonlocal current_history\n",
    "        update_left_image(i)\n",
    "\n",
    "        # Base frame with current active track overlays\n",
    "        frame, history = compute_frame(i, active_segs)\n",
    "        current_history = history\n",
    "\n",
    "        current_abs_frame = slider.value + start_frame\n",
    "\n",
    "        # Draw fully completed manual tracks up to current frame\n",
    "        for track in manual_tracks:\n",
    "            if current_abs_frame <= track[-1][0]:\n",
    "                frame = draw_manual_track_wrapper(track, frame, current_abs_frame)\n",
    "\n",
    "        # Draw in-progress manual track if present\n",
    "        if current_manual_track is not None:\n",
    "            frame = draw_manual_track_wrapper(current_manual_track, frame, current_abs_frame)\n",
    "\n",
    "        # Draw any merged tracks up to current frame\n",
    "        for snap_track_id, merged in merged_tracks:\n",
    "            if current_abs_frame <= merged[-1][0]:\n",
    "                frame = draw_merged_track_wrapper(merged, frame, current_abs_frame)\n",
    "\n",
    "        # Crop, scale, and display\n",
    "        cropped = frame[yl:yu, :]\n",
    "        h, w = cropped.shape[:2]\n",
    "        scale = display_width / w\n",
    "        resized = cv2.resize(cropped, (display_width, int(h * scale)))\n",
    "        _, buf = cv2.imencode(\".png\", resized)\n",
    "        img_widget.value = buf.tobytes()\n",
    "\n",
    "    # Initial render\n",
    "    update_image(0)\n",
    "\n",
    "    # React to slider movement\n",
    "    slider.observe(lambda change: update_image(change[\"new\"]) if change[\"name\"] == \"value\" else None, names=\"value\")\n",
    "\n",
    "    # Small inline editor (trim start/end of a selected track)\n",
    "    track_label = widgets.Label(value=\"\")\n",
    "    remove_label = widgets.Label(value=\"Remove\")\n",
    "    edit_start = widgets.IntText(value=0, description=\"Start\")\n",
    "    edit_end = widgets.IntText(value=0, description=\"End\")\n",
    "    apply_button = widgets.Button(description=\"Apply\")\n",
    "    cancel_button = widgets.Button(description=\"Cancel\")\n",
    "    edit_controls = widgets.VBox([edit_start, edit_end])\n",
    "    button_box = widgets.HBox([apply_button, cancel_button])\n",
    "    edit_box = widgets.VBox([remove_label, edit_controls, button_box])\n",
    "\n",
    "    # Merge a manual segment into an existing track if snapped at one/both ends\n",
    "    def merge_manual_track(manual_track):\n",
    "        start_snap = manual_track[0][3] if len(manual_track[0]) > 3 else None\n",
    "        end_snap = manual_track[-1][3] if len(manual_track[-1]) > 3 else None\n",
    "        if start_snap is None and end_snap is None:\n",
    "            return None\n",
    "\n",
    "        # Convert to absolute (frame, pos, colour), mark endpoints in green\n",
    "        manual_abs = []\n",
    "        for idx, pt in enumerate(manual_track):\n",
    "            f_val = pt[0]\n",
    "            pos = pt[1]\n",
    "            col = pt[2]\n",
    "            if (idx == 0 and start_snap is not None) or (idx == len(manual_track) - 1 and end_snap is not None):\n",
    "                col = green\n",
    "            manual_abs.append((f_val, pos, col))\n",
    "\n",
    "        merged = []\n",
    "\n",
    "        # If snapped to two different tracks, stitch start + manual + end\n",
    "        if start_snap is not None and end_snap is not None and start_snap != end_snap:\n",
    "            if start_snap in active_segs and end_snap in active_segs:\n",
    "                existing_pts_start = []\n",
    "                for f in sorted(active_segs[start_snap].keys()):\n",
    "                    for p in active_segs[start_snap][f]:\n",
    "                        existing_pts_start.append((f, (p[0], p[1]), p[2]))\n",
    "\n",
    "                existing_pts_end = []\n",
    "                for f in sorted(active_segs[end_snap].keys()):\n",
    "                    for p in active_segs[end_snap][f]:\n",
    "                        existing_pts_end.append((f, (p[0], p[1]), p[2]))\n",
    "\n",
    "                # Avoid duplicating join points\n",
    "                if existing_pts_start and existing_pts_start[-1][0] == manual_abs[0][0]:\n",
    "                    existing_pts_start.pop()\n",
    "                if existing_pts_end and existing_pts_end[0][0] == manual_abs[-1][0]:\n",
    "                    existing_pts_end.pop(0)\n",
    "\n",
    "                merged = existing_pts_start + manual_abs + existing_pts_end\n",
    "            else:\n",
    "                # If one side is missing, extend the one that exists\n",
    "                snap_track = start_snap if start_snap in active_segs else end_snap\n",
    "                if snap_track not in active_segs:\n",
    "                    return None\n",
    "                existing_pts = []\n",
    "                for f in sorted(active_segs[snap_track].keys()):\n",
    "                    for p in active_segs[snap_track][f]:\n",
    "                        existing_pts.append((f, (p[0], p[1]), p[2]))\n",
    "                if start_snap is not None:\n",
    "                    if existing_pts and existing_pts[-1][0] == manual_abs[0][0]:\n",
    "                        existing_pts.pop()\n",
    "                    merged = existing_pts + manual_abs\n",
    "                else:\n",
    "                    if existing_pts and existing_pts[0][0] == manual_abs[-1][0]:\n",
    "                        existing_pts.pop(0)\n",
    "                    merged = manual_abs + existing_pts\n",
    "        else:\n",
    "            # Snapped to only one track: prepend or append manual segment\n",
    "            snap_track = start_snap if start_snap is not None else end_snap\n",
    "            if snap_track not in active_segs:\n",
    "                return None\n",
    "            existing_pts = []\n",
    "            for f in sorted(active_segs[snap_track].keys()):\n",
    "                for p in active_segs[snap_track][f]:\n",
    "                    existing_pts.append((f, (p[0], p[1]), p[2]))\n",
    "            if start_snap is not None:\n",
    "                if existing_pts and existing_pts[-1][0] == manual_abs[0][0]:\n",
    "                    existing_pts.pop()\n",
    "                merged = existing_pts + manual_abs\n",
    "            else:\n",
    "                if existing_pts and existing_pts[0][0] == manual_abs[-1][0]:\n",
    "                    existing_pts.pop(0)\n",
    "                merged = manual_abs + existing_pts\n",
    "\n",
    "        merged.sort(key=lambda x: x[0])\n",
    "        return (start_snap if start_snap is not None else end_snap, merged)\n",
    "\n",
    "    # Track where a manual drawing action began in the undo stack\n",
    "    manual_track_undo_start = None\n",
    "\n",
    "    # Toggle for drawing mode\n",
    "    def on_draw_toggle_change(change):\n",
    "        nonlocal current_manual_track, manual_tracks, active_segs, merged_tracks, manual_track_undo_start\n",
    "        if change['new']:\n",
    "            # Started drawing\n",
    "            current_manual_track = []\n",
    "            manual_track_undo_start = len(undo_stack)\n",
    "        else:\n",
    "            # Stopped drawing: finalise or merge\n",
    "            if current_manual_track is not None and len(current_manual_track) > 1:\n",
    "                if allow_merge_toggle.value:\n",
    "                    merge_result = merge_manual_track(current_manual_track)\n",
    "                    if merge_result is not None:\n",
    "                        snap_track_id, merged = merge_result\n",
    "                        removed_data = active_segs.pop(snap_track_id, None)  # remove old\n",
    "                        merged_tracks.append((snap_track_id, merged))        # add merged\n",
    "                        undo_stack.append((\"merge\", snap_track_id, removed_data))\n",
    "                        track_label.value = \"Merged track \" + str(snap_track_id)\n",
    "                    else:\n",
    "                        # Not snapped: store as standalone manual track\n",
    "                        manual_tracks.append(current_manual_track)\n",
    "                        if manual_track_undo_start is not None:\n",
    "                            # Remove in-progress draw actions from undo stack\n",
    "                            while len(undo_stack) > manual_track_undo_start:\n",
    "                                undo_stack.pop()\n",
    "                            manual_track_undo_start = None\n",
    "                        undo_stack.append((\"complete_track\",))\n",
    "                else:\n",
    "                    manual_tracks.append(current_manual_track)\n",
    "                    undo_stack.append((\"complete_track\",))\n",
    "            current_manual_track = None\n",
    "            update_image(slider.value)\n",
    "\n",
    "    draw_toggle.observe(on_draw_toggle_change, names=\"value\")\n",
    "\n",
    "    # Mouse click handler for picking/placing points\n",
    "    def handle_click(event):\n",
    "        nonlocal selected_track, current_manual_track\n",
    "        x = event.get(\"relativeX\", event.get(\"offsetX\"))\n",
    "        y = event.get(\"relativeY\", event.get(\"offsetY\"))\n",
    "        if x is None or y is None:\n",
    "            return\n",
    "\n",
    "        # Map widget coords back to original ROI coordinates\n",
    "        cropped = compute_frame(slider.value, active_segs)[0][yl:yu, :]\n",
    "        h, w = cropped.shape[:2]\n",
    "        scale = display_width / w\n",
    "        orig_x = int(x / scale)\n",
    "        orig_y = int(y / scale + yl)\n",
    "\n",
    "        if draw_toggle.value:\n",
    "            # Enforce strictly consecutive frames when drawing\n",
    "            if slider.value == 0:\n",
    "                return\n",
    "            absolute_frame = slider.value + start_frame\n",
    "            if current_manual_track:\n",
    "                last_frame = current_manual_track[-1][0]\n",
    "                if absolute_frame != last_frame + 1:\n",
    "                    return\n",
    "\n",
    "            dot_color = yellow\n",
    "            snapped_track = None\n",
    "            current_frame_number = absolute_frame\n",
    "\n",
    "            # Optionally snap to closest detection to assist accurate clicking\n",
    "            if snap_track_toggle.value and current_frame_number in detection_markers:\n",
    "                best = None\n",
    "                best_dist = 15  # pixel threshold for snapping\n",
    "                for d in detection_markers[current_frame_number]:\n",
    "                    dist = np.hypot(orig_x - d[0], orig_y - d[1])\n",
    "                    if dist < best_dist:\n",
    "                        best = d\n",
    "                        best_dist = dist\n",
    "                if best is not None:\n",
    "                    orig_x, orig_y = best\n",
    "\n",
    "                    # If merging is allowed, check if near an existing track endpoint\n",
    "                    _, history = compute_frame(slider.value, active_segs)\n",
    "                    if allow_merge_toggle.value:\n",
    "                        for track_id, pts in history.items():\n",
    "                            if pts:\n",
    "                                first_pt = pts[0]\n",
    "                                last_pt = pts[-1]\n",
    "                                if np.hypot(orig_x - first_pt[0], orig_y - first_pt[1]) < 15:\n",
    "                                    dot_color = green\n",
    "                                    snapped_track = track_id\n",
    "                                    break\n",
    "                                elif np.hypot(orig_x - last_pt[0], orig_y - last_pt[1]) < 15:\n",
    "                                    dot_color = green\n",
    "                                    snapped_track = track_id\n",
    "                                    break\n",
    "\n",
    "            # Begin or extend manual track\n",
    "            if current_manual_track is None:\n",
    "                current_manual_track = []\n",
    "            current_manual_track.append((absolute_frame, (orig_x, orig_y), dot_color, snapped_track))\n",
    "            undo_stack.append((\"draw_point\",))\n",
    "            update_image(slider.value)\n",
    "        else:\n",
    "            # Selection mode: pick an existing track near the click\n",
    "            threshold = 5\n",
    "            sel_track = \"\"\n",
    "            min_dist = float(\"inf\")\n",
    "            for pid, pts in current_history.items():\n",
    "                for pt in pts:\n",
    "                    dist = np.hypot(orig_x - pt[0], orig_y - pt[1])\n",
    "                    if dist < threshold and dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        sel_track = pid\n",
    "            selected_track = sel_track\n",
    "            track_label.value = str(selected_track)\n",
    "\n",
    "    # Connect click events to the main image widget\n",
    "    click_ev = ipyevents.Event(source=img_widget, watched_events=[\"click\"])\n",
    "    click_ev.on_dom_event(handle_click)\n",
    "\n",
    "    # Apply trimming edits to a selected track (remove start/end segments)\n",
    "    def apply_edit(b):\n",
    "        nonlocal active_segs, selected_track\n",
    "        if not selected_track:\n",
    "            return\n",
    "        frames = sorted(active_segs[selected_track].keys())\n",
    "        if not frames:\n",
    "            return\n",
    "\n",
    "        # Save for undo\n",
    "        original_data = copy.deepcopy(active_segs[selected_track])\n",
    "        undo_stack.append((\"remove_link\", selected_track, original_data))\n",
    "\n",
    "        rs = edit_start.value\n",
    "        re = edit_end.value\n",
    "        if rs + re >= len(frames):\n",
    "            # If removing everything, drop the track entirely\n",
    "            del active_segs[selected_track]\n",
    "        else:\n",
    "            # Keep the middle segment after trimming\n",
    "            new_frames = frames[rs:len(frames) - re]\n",
    "            new_data = {f: active_segs[selected_track][f] for f in new_frames}\n",
    "            active_segs[selected_track] = new_data\n",
    "        update_image(slider.value)\n",
    "\n",
    "    def cancel_edit(b):\n",
    "        nonlocal selected_track\n",
    "        selected_track = None\n",
    "\n",
    "    apply_button.on_click(apply_edit)\n",
    "    cancel_button.on_click(cancel_edit)\n",
    "\n",
    "    # Undo last action from the undo stack\n",
    "    def on_undo_button_clicked(b):\n",
    "        nonlocal current_manual_track, manual_tracks, active_segs, selected_track\n",
    "        if not undo_stack:\n",
    "            track_label.value = \"Nothing to undo\"\n",
    "            return\n",
    "        action = undo_stack.pop()\n",
    "\n",
    "        if action[0] == \"draw_point\":\n",
    "            if draw_toggle.value and current_manual_track:\n",
    "                current_manual_track.pop()\n",
    "            else:\n",
    "                if manual_tracks:\n",
    "                    manual_tracks.pop()\n",
    "\n",
    "        elif action[0] == \"complete_track\":\n",
    "            if manual_tracks:\n",
    "                manual_tracks.pop()\n",
    "\n",
    "        elif action[0] == \"remove_link\":\n",
    "            track_id, original_data = action[1], action[2]\n",
    "            active_segs[track_id] = original_data\n",
    "\n",
    "        elif action[0] == \"merge\":\n",
    "            snap_track_id = action[1]\n",
    "            removed_data = action[2]\n",
    "            # Remove the merged overlay and restore the original track data\n",
    "            merged_tracks[:] = [mt for mt in merged_tracks if mt[0] != snap_track_id]\n",
    "            if removed_data is not None:\n",
    "                active_segs[snap_track_id] = removed_data\n",
    "\n",
    "        update_image(slider.value)\n",
    "\n",
    "    undo_button.on_click(on_undo_button_clicked)\n",
    "\n",
    "    # Save the current (possibly edited) set of tracks to CSV\n",
    "    def on_save_button_clicked(b):\n",
    "        brown = (29, 101, 181)\n",
    "        yellow = (0, 255, 255)\n",
    "        green = (0, 255, 0)\n",
    "\n",
    "        def color_to_str(color):\n",
    "            if color == brown:\n",
    "                return \"brown\"\n",
    "            elif color == green:\n",
    "                return \"green\"\n",
    "            elif color == yellow:\n",
    "                return \"yellow\"\n",
    "            else:\n",
    "                return \"brown\"\n",
    "\n",
    "        rows = []\n",
    "\n",
    "        # Existing (possibly trimmed) active tracks\n",
    "        for tid, frames_dict in active_segs.items():\n",
    "            for f in sorted(frames_dict.keys()):\n",
    "                for pos in frames_dict[f]:\n",
    "                    rows.append({\n",
    "                        \"unique_id\": tid,\n",
    "                        \"frame\": f,\n",
    "                        \"x\": pos[0],\n",
    "                        \"y\": pos[1],\n",
    "                        \"color\": color_to_str(pos[2])\n",
    "                    })\n",
    "\n",
    "        # Merged tracks are stored with a suffixed id\n",
    "        for snap_track_id, merged in merged_tracks:\n",
    "            new_id = str(snap_track_id) + \"_manual\"\n",
    "            for (f, pos, col) in merged:\n",
    "                rows.append({\n",
    "                    \"unique_id\": new_id,\n",
    "                    \"frame\": f,\n",
    "                    \"x\": pos[0],\n",
    "                    \"y\": pos[1],\n",
    "                    \"color\": color_to_str(col)\n",
    "                })\n",
    "\n",
    "        # Completed standalone manual tracks get autogenerated ids\n",
    "        for track in manual_tracks:\n",
    "            new_id = generate_manual_track_id()\n",
    "            for (f, pos, col, _) in track:\n",
    "                rows.append({\n",
    "                    \"unique_id\": new_id,\n",
    "                    \"frame\": f,\n",
    "                    \"x\": pos[0],\n",
    "                    \"y\": pos[1],\n",
    "                    \"color\": color_to_str(col)\n",
    "                })\n",
    "\n",
    "        # If currently drawing, persist partial manual track as well\n",
    "        if current_manual_track and len(current_manual_track) > 0:\n",
    "            new_id = generate_manual_track_id()\n",
    "            for (f, pos, col, _) in current_manual_track:\n",
    "                rows.append({\n",
    "                    \"unique_id\": new_id,\n",
    "                    \"frame\": f,\n",
    "                    \"x\": pos[0],\n",
    "                    \"y\": pos[1],\n",
    "                    \"color\": color_to_str(col)\n",
    "                })\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(updated_file, index=False)\n",
    "        track_label.value = \"Saved changes\"\n",
    "\n",
    "    save_button.on_click(on_save_button_clicked)\n",
    "\n",
    "    # Assemble the UI\n",
    "    controls = widgets.VBox([\n",
    "        video_mode_toggle, slider, draw_toggle, snap_track_toggle,\n",
    "        allow_merge_toggle, undo_button, save_button, track_label, edit_box\n",
    "    ])\n",
    "    container = widgets.HBox([left_img_widget, img_widget, controls],\n",
    "                             layout=widgets.Layout(align_items=\"center\"))\n",
    "    container.add_class(\"focusable\")\n",
    "\n",
    "    # Keyboard shortcuts with key repeat for frame stepping\n",
    "    keys_down = set()\n",
    "    repeating_tasks = {}\n",
    "\n",
    "    def handle_keyboard_event(event):\n",
    "        nonlocal keys_down, repeating_tasks\n",
    "        key = event.get(\"key\")\n",
    "\n",
    "        if event[\"type\"] == \"keydown\":\n",
    "            if key == \"e\":\n",
    "                snap_track_toggle.value = not snap_track_toggle.value\n",
    "            elif key == \"r\":\n",
    "                on_undo_button_clicked(None)\n",
    "            elif key == \"d\":\n",
    "                draw_toggle.value = not draw_toggle.value\n",
    "            elif key == \"f\":\n",
    "                on_save_button_clicked(None)\n",
    "            elif key == \"c\":\n",
    "                allow_merge_toggle.value = not allow_merge_toggle.value\n",
    "            elif key in (\"q\", \"w\"):\n",
    "                if key not in keys_down:\n",
    "                    keys_down.add(key)\n",
    "\n",
    "                    async def repeat_key_action():\n",
    "                        while key in keys_down:\n",
    "                            if key == \"q\":\n",
    "                                slider.value = max(slider.min, slider.value - 1)\n",
    "                            elif key == \"w\":\n",
    "                                slider.value = min(slider.max, slider.value + 1)\n",
    "                            await asyncio.sleep(0.1)\n",
    "\n",
    "                    repeating_tasks[key] = asyncio.create_task(repeat_key_action())\n",
    "\n",
    "        elif event[\"type\"] == \"keyup\":\n",
    "            if key in keys_down:\n",
    "                keys_down.remove(key)\n",
    "            if key in repeating_tasks:\n",
    "                repeating_tasks[key].cancel()\n",
    "                del repeating_tasks[key]\n",
    "\n",
    "    # Attach keyboard listeners to the whole container\n",
    "    keyboard_ev = ipyevents.Event(source=container, watched_events=[\"keydown\", \"keyup\"])\n",
    "    keyboard_ev.on_dom_event(handle_keyboard_event)\n",
    "\n",
    "    # Simple dark theme for the container\n",
    "    container.add_class(\"dark-container\")\n",
    "    display(HTML(\"\"\"\n",
    "    <style>\n",
    "      .dark-container { background-color: black; padding: 10px; }\n",
    "      .dark-container .widget-label, .dark-container .widget-readout, .widget-value { color: white; }\n",
    "      .focusable { outline: none; }\n",
    "    </style>\n",
    "    \"\"\"))\n",
    "\n",
    "    # Show the widget\n",
    "    display(container)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Load config and data, create normal and temporally blurred panels,\n",
    "    then launch the interactive widget for manual review/editing.\n",
    "    \"\"\"\n",
    "    (heatmap_inp, yl, yu, end_frame, cmap, tracks_csv_path, proc_params,\n",
    "     display_width, linke_thickness, updated_file) = get_config()\n",
    "\n",
    "    # Determine global max for heatmap normalisation\n",
    "    gm = find_global_max(heatmap_inp, yl, yu, end_frame)\n",
    "\n",
    "    # Prefer previously saved edits, else original tracks file\n",
    "    if os.path.exists(updated_file):\n",
    "        df_tracks = pd.read_csv(updated_file)\n",
    "    else:\n",
    "        df_tracks = pd.read_csv(tracks_csv_path)\n",
    "\n",
    "    # Load frames from the requested range\n",
    "    cap = cv2.VideoCapture(heatmap_inp)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, proc_params[\"start_frame\"])\n",
    "    frames = []\n",
    "    for _ in range(proc_params[\"start_frame\"], proc_params[\"end_frame\"] + 1):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "\n",
    "    # Build normal (JET heatmap) frames and ROI-only frames for temporal blur\n",
    "    normal_frames = []\n",
    "    roi_frames = []\n",
    "    for frame in frames:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        roi = gray[yl:yu, :]\n",
    "\n",
    "        # Normalise to [0,255] and invert before applying the colour map\n",
    "        norm = (roi / gm * 255).astype(np.uint8) if gm > 0 else np.zeros_like(roi, dtype=np.uint8)\n",
    "        heat = cv2.applyColorMap(255 - np.clip(norm, 0, 255), cmap)\n",
    "\n",
    "        hm = frame.copy()\n",
    "        hm[yl:yu, :] = heat\n",
    "        rgb_frame = cv2.cvtColor(hm, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        normal_frames.append(rgb_frame)\n",
    "        roi_frames.append(rgb_frame[yl:yu, :].copy())\n",
    "\n",
    "    # Temporal blur on ROI, then stitch back to full-height frames as a “summed” view\n",
    "    blurred_roi_frames = temporal_gaussian_blur(roi_frames, 5, 1.0)\n",
    "    summed_frames = []\n",
    "    for i, frame in enumerate(normal_frames):\n",
    "        new_frame = frame.copy()\n",
    "        new_frame[yl:yu, :] = blurred_roi_frames[i]\n",
    "        summed_frames.append(new_frame)\n",
    "\n",
    "    # Convert the tracks DataFrame to quick-lookup segments by id and frame\n",
    "    segs = prepare_segments(df_tracks)\n",
    "\n",
    "    # Launch interactive widget\n",
    "    interactive_video_widget(normal_frames, summed_frames, segs, proc_params[\"start_frame\"],\n",
    "                             display_width, linke_thickness, yl, yu, updated_file)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refined Tracked Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_config():\n",
    "    \"\"\"\n",
    "    Centralise file paths and rendering/processing parameters.\n",
    "    Returns:\n",
    "        heatmap_inp (str): path to input video.\n",
    "        cmap (int): OpenCV colour map for heatmap overlay.\n",
    "        tracks_csv_path (str): path to CSV with track points.\n",
    "        proc_params (dict): processing config (frame range, sizes, etc.).\n",
    "        base (str): base output directory.\n",
    "        output_format (str): container/codec choice (\"mp4\" or \"avi\").\n",
    "    \"\"\"\n",
    "    base = \"/Users/Ricardo/Desktop/Y4 Lab code/Work 0.3K\"\n",
    "    video_folder = \"/Users/Ricardo/Desktop/Y4 Lab code/Cooldown 10\"\n",
    "    video_filename = \"_video (0).mp4\"\n",
    "    heatmap_inp = os.path.join(video_folder, video_filename)\n",
    "\n",
    "    cmap = cv2.COLORMAP_JET\n",
    "\n",
    "    # Input tracks CSV: columns expected ['unique_id','frame','x','y']\n",
    "    tracks_csv_path = os.path.join(base, \"draw_tracks.csv\")\n",
    "\n",
    "    # Main processing parameters\n",
    "    proc_params = {\n",
    "        \"start_frame\": 11,     # index of first frame to load/process (0-based)\n",
    "        \"end_frame\": 311,      # last absolute frame index to process (inclusive)\n",
    "        \"target_height\": 1080, # output panel height (each panel is resized to this)\n",
    "        \"y_min\": 100,          # top of ROI (rows are [y_min:y_max])\n",
    "        \"y_max\": 900,          # bottom of ROI (exclusive)\n",
    "        \"speed_factor\": 1,     # reserved (not used here) for fast/slow playback\n",
    "        \"bar_thickness\": 35    # width of centre separator with frame counter text\n",
    "    }\n",
    "\n",
    "    output_format = \"mp4\"      # choose \"mp4\" (H.264) or \"avi\" (MJPG)\n",
    "\n",
    "    return heatmap_inp, cmap, tracks_csv_path, proc_params, base, output_format\n",
    "\n",
    "\n",
    "def find_global_max(video_path, y_min, y_max, end_frame):\n",
    "    \"\"\"\n",
    "    Scan frames up to end_frame to get the global max grey intensity in the ROI.\n",
    "    Used to normalise the heatmap so colour scaling is consistent across frames.\n",
    "\n",
    "    Args:\n",
    "        video_path: path to video.\n",
    "        y_min, y_max: ROI vertical bounds.\n",
    "        end_frame: last frame index to consider.\n",
    "\n",
    "    Returns:\n",
    "        gm (int): global maximum pixel value within ROI across scanned frames.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    gm = 0\n",
    "    for _ in range(end_frame + 1):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        roi = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)[y_min:y_max, :]\n",
    "        gm = max(gm, int(roi.max()))\n",
    "    cap.release()\n",
    "    return gm\n",
    "\n",
    "\n",
    "def prepare_segments(tracks):\n",
    "    \"\"\"\n",
    "    Convert the tracks DataFrame into an indexable structure by id then frame.\n",
    "\n",
    "    Input DataFrame columns expected:\n",
    "        - unique_id: track identifier (string or int)\n",
    "        - frame: absolute frame number (int)\n",
    "        - x, y: integer pixel coordinates\n",
    "\n",
    "    Returns:\n",
    "        segs (dict):\n",
    "            {\n",
    "              unique_id: {\n",
    "                frame_number: [(x, y), (x, y), ...],\n",
    "                ...\n",
    "              },\n",
    "              ...\n",
    "            }\n",
    "    \"\"\"\n",
    "    segs = {}\n",
    "    for _, r in tracks.iterrows():\n",
    "        pid = r[\"unique_id\"]\n",
    "        f, x, y = int(r[\"frame\"]), int(round(r[\"x\"])), int(round(r[\"y\"]))\n",
    "        segs.setdefault(pid, {}).setdefault(f, []).append((x, y))\n",
    "    return segs\n",
    "\n",
    "\n",
    "def draw_tracks(frame, tracks, history, fc, last_det, link_thickness):\n",
    "    \"\"\"\n",
    "    Draw track paths and points up to the current frame.\n",
    "\n",
    "    Args:\n",
    "        frame (np.ndarray): BGR frame to draw on.\n",
    "        tracks (dict): output of prepare_segments().\n",
    "        history (dict): mutable; stores concatenated points per track across frames.\n",
    "        fc (int): current absolute frame number being drawn.\n",
    "        last_det (dict): mutable; last frame each track was detected (for gap reset).\n",
    "        link_thickness (int): line thickness for path segments.\n",
    "\n",
    "    Returns:\n",
    "        The input frame with white points and black path lines rendered.\n",
    "    \"\"\"\n",
    "    dot_radius = 1\n",
    "    detected = set()\n",
    "\n",
    "    # Aggregate current-frame detections into the running history\n",
    "    for pid, frames_dict in tracks.items():\n",
    "        if fc in frames_dict:\n",
    "            detected.add(pid)\n",
    "            # If a gap occurred, reset the path so lines don't jump across time\n",
    "            if pid in last_det and fc != last_det[pid] + 1:\n",
    "                history[pid] = []\n",
    "            last_det[pid] = fc\n",
    "            history.setdefault(pid, []).extend(frames_dict[fc])\n",
    "\n",
    "    # Draw each track's accumulated path and points\n",
    "    for pid in list(history):\n",
    "        if pid in detected:\n",
    "            pts = history[pid]\n",
    "            if len(pts) >= 2:\n",
    "                # Path as black polylines between consecutive points\n",
    "                for pt1, pt2 in zip(pts, pts[1:]):\n",
    "                    cv2.line(frame, pt1, pt2, (0, 0, 0), link_thickness)\n",
    "                # Points as small white dots\n",
    "                for pt in pts:\n",
    "                    cv2.circle(frame, pt, dot_radius, (255, 255, 255), -1)\n",
    "            else:\n",
    "                # Single isolated point: draw just the dot\n",
    "                pt = (int(pts[0][0]), int(pts[0][1]))\n",
    "                cv2.circle(frame, pt, dot_radius, (255, 255, 255), -1)\n",
    "        else:\n",
    "            # If the track doesn't appear this frame, drop it from history\n",
    "            history.pop(pid)\n",
    "            last_det.pop(pid, None)\n",
    "    return frame\n",
    "\n",
    "\n",
    "def apply_heatmap(frame, y_min, y_max, gm, cmap):\n",
    "    \"\"\"\n",
    "    Colourise a frame's ROI using an OpenCV colour map and global normalisation.\n",
    "\n",
    "    Args:\n",
    "        frame: BGR frame (modified in place).\n",
    "        y_min, y_max: ROI vertical bounds.\n",
    "        gm: global maximum for normalisation (avoid frame-to-frame colour shifts).\n",
    "        cmap: cv2 colormap constant (e.g., COLORMAP_JET).\n",
    "\n",
    "    Returns:\n",
    "        The same frame with its ROI replaced by the heatmap colourised ROI.\n",
    "    \"\"\"\n",
    "    roi = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)[y_min:y_max, :]\n",
    "    # Normalise to [0,255] using global max; clip for safety\n",
    "    norm = (roi / gm * 255).astype(np.uint8)\n",
    "    frame[y_min:y_max, :] = cv2.applyColorMap(np.clip(norm, 0, 255), cmap)\n",
    "    return frame\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load configuration and inputs\n",
    "    heatmap_inp, cmap, tracks_csv_path, proc_params, base, output_format = get_config()\n",
    "\n",
    "    # Read track CSV and pre-index by track id then frame\n",
    "    df_tracks = pd.read_csv(tracks_csv_path)\n",
    "    segs = prepare_segments(df_tracks)\n",
    "\n",
    "    # Determine global max intensity inside ROI for consistent heatmap scaling\n",
    "    gm = find_global_max(heatmap_inp, proc_params[\"y_min\"], proc_params[\"y_max\"], proc_params[\"end_frame\"])\n",
    "\n",
    "    # Read the needed span of frames from the source video\n",
    "    cap = cv2.VideoCapture(heatmap_inp)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, proc_params[\"start_frame\"])\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        # Stop if out of frames or we passed the requested end_frame\n",
    "        if not ret or cap.get(cv2.CAP_PROP_POS_FRAMES) > proc_params[\"end_frame\"]:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "\n",
    "    # Create heatmap-coloured frames (modifies ROI only)\n",
    "    normal_frames = [apply_heatmap(f, proc_params[\"y_min\"], proc_params[\"y_max\"], gm, cmap) for f in frames]\n",
    "\n",
    "    # State for drawing paths across frames\n",
    "    history, last_det = {}, {}\n",
    "\n",
    "    # Compute output panel sizes based on ROI scaling to target height\n",
    "    roi_height = proc_params[\"y_max\"] - proc_params[\"y_min\"]\n",
    "    target_height = proc_params[\"target_height\"]\n",
    "    scale = target_height / roi_height\n",
    "    resized_width = int(normal_frames[0].shape[1] * scale)\n",
    "\n",
    "    # Many codecs require even dimensions — pad width/height if needed\n",
    "    if resized_width % 2 != 0:\n",
    "        resized_width += 1\n",
    "    if target_height % 2 != 0:\n",
    "        target_height += 1\n",
    "\n",
    "    # Get FPS from the video for consistent output timing\n",
    "    cap = cv2.VideoCapture(heatmap_inp)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "\n",
    "    # Combined output is: [heatmap panel] + [vertical bar] + [heatmap+tracks panel]\n",
    "    combined_width = 2 * resized_width + proc_params[\"bar_thickness\"]\n",
    "\n",
    "    # Choose codec based on output format\n",
    "    if output_format.lower() == \"mp4\":\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"avc1\")  # H.264 in MP4 container (platform dependent)\n",
    "    elif output_format.lower() == \"avi\":\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")  # Motion JPEG in AVI container\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported output format: {output_format}\")\n",
    "\n",
    "    combined_video = os.path.join(base, f\"Combined_Video_WhiteTracks.{output_format}\")\n",
    "    out_combined = cv2.VideoWriter(combined_video, fourcc, fps, (combined_width, target_height))\n",
    "\n",
    "    # Render loop: build each combined frame and write it out\n",
    "    for i in range(len(normal_frames)):\n",
    "        fc = proc_params[\"start_frame\"] + i           # absolute frame counter\n",
    "        display_frame = i + 1                         # human-friendly (1-based) counter\n",
    "\n",
    "        normal_frame = normal_frames[i]\n",
    "\n",
    "        # Draw tracks on a copy so we can show both raw heatmap and overlay side-by-side\n",
    "        raw_frame = draw_tracks(normal_frame.copy(), segs, history, fc, last_det, 1)\n",
    "\n",
    "        # Crop to ROI, then resize each panel to the target height\n",
    "        normal_cropped = normal_frame[proc_params[\"y_min\"]:proc_params[\"y_max\"], :]\n",
    "        raw_cropped = raw_frame[proc_params[\"y_min\"]:proc_params[\"y_max\"], :]\n",
    "        normal_resized = cv2.resize(normal_cropped, (resized_width, target_height))\n",
    "        raw_resized = cv2.resize(raw_cropped, (resized_width, target_height))\n",
    "\n",
    "        # Separator bar with frame number text (white on black)\n",
    "        bar = np.zeros((target_height, proc_params[\"bar_thickness\"], 3), dtype=np.uint8)\n",
    "        text = str(display_frame)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 0.5\n",
    "        thickness = 1\n",
    "        text_size, _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "        text_x = (proc_params[\"bar_thickness\"] - text_size[0]) // 2\n",
    "        text_y = 50  # fixed vertical offset for readability\n",
    "        cv2.putText(bar, text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness)\n",
    "\n",
    "        # Concatenate panels: left (heatmap only) | bar | right (heatmap + tracks)\n",
    "        combined_frame = np.hstack([normal_resized, bar, raw_resized])\n",
    "\n",
    "        out_combined.write(combined_frame)\n",
    "\n",
    "    out_combined.release()\n",
    "    print(\"Combined video with raw tracks created:\", combined_video)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
